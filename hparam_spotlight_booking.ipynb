{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* hparams search:\n",
    "\n",
    "https://github.com/maciejkula/spotlight/blob/master/examples/movielens_sequence/movielens_sequence.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install pandas numpy scipy ipython -y\n",
    "# !conda install -c maciejkula -c pytorch spotlight -y\n",
    "# !pip install spotlight\n",
    "\n",
    "# !conda install pytorch torchvision  cudatoolkit=10.2 -c pytorch --force-reinstall -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append(\"../../\")\n",
    "import os\n",
    "# import papermill as pm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from reco_utils.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k, get_top_k_items, auc\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit, GridSearchCV, GroupKFold\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from spotlight.cross_validation import random_train_test_split, user_based_train_test_split\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "from spotlight.evaluation import mrr_score\n",
    "from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
    "from spotlight.cross_validation import user_based_train_test_split\n",
    "from spotlight.datasets.synthetic import generate_sequential\n",
    "from spotlight.evaluation import sequence_mrr_score\n",
    "from spotlight.sequence.implicit import ImplicitSequenceModel\n",
    "from spotlight.interactions import Interactions\n",
    "import torch\n",
    "from spotlight.evaluation import sequence_mrr_score,precision_recall_score\n",
    "# from spotlight.evaluation import sequence_precision_recall_score # https://maciejkula.github.io/spotlight/evaluation.html#spotlight.evaluation.sequence_precision_recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from spotlight_hyperparams_movielens_sequence import *\n",
    "\n",
    "NUM_SAMPLES = 15\n",
    "\n",
    "# LEARNING_RATES = [2e-3, 1e-2, 5 * 1e-2, 1e-1]\n",
    "# LOSSES = ['bpr', 'hinge', 'adaptive_hinge', 'pointwise']\n",
    "# BATCH_SIZE = [16,64, 128, 512]\n",
    "# EMBEDDING_DIM = [ 64, 128, 256]\n",
    "# # N_ITER = list(range(5, 20))\n",
    "# N_ITER = [10,20,40]\n",
    "# L2 =[1e-6, 1e-4,  5e-3,1e-2, 0.0]  ### [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 0.0] \n",
    "\n",
    "random_state = np.random.RandomState(100)\n",
    "\n",
    "CUDA = (os.environ.get('CUDA') is not None or\n",
    "        shutil.which('nvidia-smi') is not None)\n",
    "print(CUDA)\n",
    "CUDA = False ## pytorch issues\n",
    "\n",
    "max_sequence_length = 16\n",
    "min_sequence_length = 4\n",
    "random_state = np.random.RandomState(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_precision_recall_score(model, test, k=1, exclude_preceding=False):\n",
    "    \"\"\"\n",
    "    https://maciejkula.github.io/spotlight/_modules/spotlight/evaluation.html#sequence_precision_recall_score\n",
    "    \n",
    "    Compute sequence precision and recall scores. Each sequence\n",
    "    in test is split into two parts: the first part, containing\n",
    "    all but the last k elements, is used to predict the last k\n",
    "    elements.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    model: fitted instance of a recommender model\n",
    "        The model to evaluate.\n",
    "    test: :class:`spotlight.interactions.SequenceInteractions`\n",
    "        Test interactions.\n",
    "    exclude_preceding: boolean, optional\n",
    "        When true, items already present in the sequence will\n",
    "        be excluded from evaluation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    mrr scores: numpy array of shape (num_users,)\n",
    "        Array of MRR scores for each sequence in test.\n",
    "    \"\"\"\n",
    "    sequences = test.sequences[:, :-k]\n",
    "    targets = test.sequences[:, -k:]\n",
    "    precision_recalls = []\n",
    "    for i in range(len(sequences)):\n",
    "        predictions = -model.predict(sequences[i])\n",
    "        if exclude_preceding:\n",
    "            predictions[sequences[i]] = FLOAT_MAX\n",
    "\n",
    "        predictions = predictions.argsort()[:k]\n",
    "        precision_recall = _get_precision_recall(predictions, targets[i], k)\n",
    "        precision_recalls.append(precision_recall)\n",
    "\n",
    "    precision = np.array(precision_recalls)[:, 0]\n",
    "    recall = np.array(precision_recalls)[:, 1]\n",
    "    return precision, recall\n",
    "\n",
    "\n",
    "def _get_precision_recall(predictions, targets, k):\n",
    "\n",
    "    predictions = predictions[:k]\n",
    "    num_hit = len(set(predictions).intersection(set(targets)))\n",
    "\n",
    "    return float(num_hit) / len(predictions), float(num_hit) / len(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 4\n",
    "\n",
    "# # Model parameters\n",
    "# EPOCHS = 10\n",
    "# BATCH_SIZE =  256#1024\n",
    "\n",
    "SEED = 0  # Set None for non-deterministic results\n",
    "random_state = np.random.RandomState(100)\n",
    "\n",
    "# CUDA = (os.environ.get('CUDA') is not None or\n",
    "#         shutil.which('nvidia-smi') is not None)\n",
    "# print(CUDA)\n",
    "CUDA = False\n",
    "\n",
    "# user_file = \"../../tests/resources/deeprec/lightgcn/user_embeddings.csv\"\n",
    "# item_file = \"../../tests/resources/deeprec/lightgcn/item_embeddings.csv\"\n",
    "\n",
    "TRAIN_FILE_PATH = os.path.normpath(r\"C:\\Users\\Dan Ofer\\Desktop\\Stuff\\booking_wisdom\\booking_train_set.csv\") #\"/content/drive/MyDrive/booking_wisdom/booking_train_set.csv\" #\"booking_train_set.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spotlight relevant examples:\n",
    "\n",
    "https://github.com/maciejkula/spotlight/blob/master/examples/movielens_sequence/movielens_sequence.py\n",
    "\n",
    "https://github.com/maciejkula/spotlight/issues/172\n",
    "* Dataset creation/loading + get predictions (sequence)\n",
    "\n",
    "Spotlight hyperparameter tuning:\n",
    "https://github.com/maciejkula/spotlight/blob/master/examples/movielens_sequence/movielens_sequence.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = movielens.load_pandas_df(size=MOVIELENS_DATA_SIZE) ## orig \n",
    "# print(df.dtypes)\n",
    "# print(df.shape)\n",
    "# ## expected columns: ['userID', 'itemID', 'rating', 'timestamp'] (last as float), others as number\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max rows count    140250.000000\n",
      "mean          6.113198\n",
      "std           2.828479\n",
      "min           4.000000\n",
      "25%           4.000000\n",
      "50%           5.000000\n",
      "75%           7.000000\n",
      "max          48.000000\n",
      "Name: total_rows, dtype: float64\n",
      "132353\n",
      "132212\n",
      "nunique\n",
      " userID       26132\n",
      "itemID       16875\n",
      "timestamp      425\n",
      "dtype: int64\n",
      "(132212, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81631</th>\n",
       "      <td>0</td>\n",
       "      <td>64876</td>\n",
       "      <td>2016-06-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81632</th>\n",
       "      <td>0</td>\n",
       "      <td>55128</td>\n",
       "      <td>2016-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81633</th>\n",
       "      <td>0</td>\n",
       "      <td>9608</td>\n",
       "      <td>2016-06-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81634</th>\n",
       "      <td>0</td>\n",
       "      <td>31817</td>\n",
       "      <td>2016-06-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81635</th>\n",
       "      <td>0</td>\n",
       "      <td>36170</td>\n",
       "      <td>2016-06-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userID  itemID  timestamp\n",
       "81631       0   64876 2016-06-18\n",
       "81632       0   55128 2016-06-20\n",
       "81633       0    9608 2016-06-22\n",
       "81634       0   31817 2016-06-24\n",
       "81635       0   36170 2016-06-25"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = movielens.load_pandas_df(size=MOVIELENS_DATA_SIZE) ## orig \n",
    "df = pd.read_csv(TRAIN_FILE_PATH,\n",
    "                     nrows=140_500,\n",
    "                     parse_dates=[\"checkin\"],infer_datetime_format=True,usecols=[\"utrip_id\",\"city_id\",\"checkin\"])\n",
    "user_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "## drop consecutive elements (need to do within group, and to order, and what about updating checkout date?)\n",
    "## 0 cases if we also use checkin or checkout. \n",
    "## The \"last\"  criteria does drop rows! Do we want or not want it???\n",
    "## We also +- need to merge with total duration data\n",
    "\n",
    "df[\"utrip_id\"] = user_encoder.fit_transform(df[\"utrip_id\"])\n",
    "df = df.groupby(\"utrip_id\").filter(lambda x: len(x) >= 4) # keep only trips with at least 4\n",
    "\n",
    "#####\n",
    "df[\"row_num\"] = df.groupby(\"utrip_id\")[\"checkin\"].rank(ascending=True,pct=False).astype(int)\n",
    "utrip_counts = df[\"utrip_id\"].value_counts()\n",
    "df[\"total_rows\"] = df[\"utrip_id\"].map(utrip_counts)\n",
    "print(\"max rows\", df[\"total_rows\"].describe())\n",
    "df[\"last\"] = (df[\"row_num\"] ==df[\"total_rows\"])#.astype(int)\n",
    "###\n",
    "df = df.loc[(df[[\"city_id\",\"utrip_id\",\"last\"]].shift() != df[[\"city_id\",\"utrip_id\",\"last\"]]).max(axis=1)]\n",
    "\n",
    "##########\n",
    "### truncate longer trips\n",
    "print(df.shape[0])\n",
    "# df = df.loc[df[\"total_rows\"]<=max_sequence_length+1]\n",
    "df = df.groupby(\"utrip_id\").tail(max_sequence_length)\n",
    "print(df.shape[0])\n",
    "##########\n",
    "\n",
    "\n",
    "df = df[[\"utrip_id\",\"city_id\",\"checkin\",\"last\"]]\n",
    "              \n",
    "df.columns = ['userID', 'itemID',  'timestamp',\"last\"] ## no rating col\n",
    "\n",
    "df.sort_values([\"userID\",\"timestamp\"],ascending=True,inplace=True) ## reinforce sort order for within groups\n",
    "# df[\"rating\"] = 1\n",
    "\n",
    "df = df[['userID', 'itemID',  'timestamp']]\n",
    "# print(df.dtypes)\n",
    "print(\"nunique\\n\",df.nunique())\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique items (city_id)\n",
      "16875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    16875.000000\n",
       "mean         7.834785\n",
       "std         36.513534\n",
       "min          1.000000\n",
       "25%          1.000000\n",
       "50%          2.000000\n",
       "75%          4.000000\n",
       "max       1239.000000\n",
       "Name: itemID, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"unique items (city_id)\")\n",
    "print(df['itemID'].nunique())\n",
    "df['itemID'].value_counts().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before uniques 16875\n",
      "unique items (city_id)\n",
      "5794\n",
      "count     5794.000000\n",
      "mean        22.818778\n",
      "std        191.057396\n",
      "min          3.000000\n",
      "25%          4.000000\n",
      "50%          6.000000\n",
      "75%         14.000000\n",
      "max      13819.000000\n",
      "Name: itemID, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ### replace rare variables (under 2 occurrences) with \"-1\" dummy OR with their hotel country! (as negative mapped number)\n",
    "city_ids_counts = df[\"itemID\"].value_counts()\n",
    "print(\"before uniques\",df[\"itemID\"].nunique())\n",
    "city_ids_counts = city_ids_counts.to_dict()\n",
    "df[\"itemID\"] = df[\"itemID\"].where(df[\"itemID\"].map(city_ids_counts)>2, -1)\n",
    "\n",
    "## run encoder on cities (due to negative and to ensure ok ordering for spotlight)\n",
    "item_encoder = LabelEncoder()\n",
    "df[\"itemID\"] = user_encoder.fit_transform(df[\"itemID\"])\n",
    "\n",
    "print(\"unique items (city_id)\")\n",
    "print(df['itemID'].nunique())\n",
    "print(df['itemID'].value_counts().describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create spotlight Interactions dataset\n",
    "    * https://github.com/maciejkula/spotlight/issues/172\n",
    "    * Could provide WEIGHTS (more weight to final row in sequence / last) \n",
    "    \n",
    "    * Getting predictions: \n",
    "    ```\n",
    "    predictions = model.predict(ids)\n",
    "\n",
    "    item_ids= (-predictions).argsort()[:10] # last 10 items\n",
    "    print(item_ids)\n",
    "    print(predictions[item_ids])\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implicit_interactions = Interactions(df['userID'].values, 1+df['itemID'].values, timestamps=df['timestamp'])\n",
    "\n",
    "# train, test = user_based_train_test_split(implicit_interactions, 0.25) # ,random_state=\n",
    "# print(\"train\",train)\n",
    "# print(\"test\",test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# sequential_interaction = train.to_sequence(max_sequence_length=9, min_sequence_length=3)\n",
    "# print(sequential_interaction)\n",
    "# test_sequential = test.to_sequence(max_sequence_length=16, min_sequence_length=4)\n",
    "# print(test_sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train <Sequence interactions dataset (17751 sequences x 16 sequence length)>\n",
      "test <Sequence interactions dataset (2904 sequences x 16 sequence length)>\n",
      "validation <Sequence interactions dataset (2881 sequences x 16 sequence length)>\n",
      "Wall time: 103 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# dataset = get_movielens_dataset('1M')\n",
    "dataset = Interactions(df['userID'].values, 1+df['itemID'].values, timestamps=df['timestamp'])\n",
    "\n",
    "train, rest = user_based_train_test_split(dataset,\n",
    "                                          test_percentage=0.25,\n",
    "                                          random_state=random_state)\n",
    "test, validation = user_based_train_test_split(rest,\n",
    "                                               test_percentage=0.5,\n",
    "                                               random_state=random_state)\n",
    "train = train.to_sequence(max_sequence_length=max_sequence_length,\n",
    "                          min_sequence_length=min_sequence_length)\n",
    "print(\"train\",train)\n",
    "test = test.to_sequence(max_sequence_length=max_sequence_length,\n",
    "                        min_sequence_length=min_sequence_length)\n",
    "print(\"test\",test)\n",
    "validation = validation.to_sequence(max_sequence_length=max_sequence_length,\n",
    "                                    min_sequence_length=min_sequence_length)\n",
    "print(\"validation\",validation)\n",
    "mode = \"lstm\" #sys.argv[1] ## model types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lstm result: {'test_mrr': 0.330401685693058, 'validation_mrr': 0.32771968962309106, 'num_negative_samples': 20, 'n_iter': 50, 'loss': 'adaptive_hinge', 'learning_rate': 0.002, 'l2': 0.0, 'embedding_dim': 256, 'batch_size': 256}\n",
      "Evaluating {'num_negative_samples': 15, 'n_iter': 50, 'loss': 'adaptive_hinge', 'learning_rate': 0.002, 'l2': 0.0, 'embedding_dim': 128, 'batch_size': 256}\n",
      "Test MRR 0.32839684116591195 val MRR 0.33631885048360144\n",
      "Evaluating {'num_negative_samples': 30, 'n_iter': 50, 'loss': 'adaptive_hinge', 'learning_rate': 0.002, 'l2': 0.0, 'embedding_dim': 128, 'batch_size': 256}\n",
      "Test MRR 0.3325081835544003 val MRR 0.3482472573988587\n",
      "Evaluating {'num_negative_samples': 60, 'n_iter': 50, 'loss': 'adaptive_hinge', 'learning_rate': 0.002, 'l2': 0.0, 'embedding_dim': 128, 'batch_size': 256}\n",
      "Test MRR 0.3464995984126844 val MRR 0.3605211799916017\n",
      "Evaluating {'num_negative_samples': 100, 'n_iter': 50, 'loss': 'adaptive_hinge', 'learning_rate': 0.002, 'l2': 0.0, 'embedding_dim': 128, 'batch_size': 256}\n",
      "Test MRR 0.3576369759768832 val MRR 0.36227514744166667\n",
      "Evaluating {'num_negative_samples': 15, 'n_iter': 90, 'loss': 'adaptive_hinge', 'learning_rate': 0.002, 'l2': 0.0, 'embedding_dim': 128, 'batch_size': 256}\n",
      "Test MRR 0.3303054325358432 val MRR 0.34584297442839645\n",
      "Evaluating {'num_negative_samples': 30, 'n_iter': 90, 'loss': 'adaptive_hinge', 'learning_rate': 0.002, 'l2': 0.0, 'embedding_dim': 128, 'batch_size': 256}\n",
      "Test MRR 0.33501175387200854 val MRR 0.35160629614074895\n",
      "Evaluating {'num_negative_samples': 60, 'n_iter': 90, 'loss': 'adaptive_hinge', 'learning_rate': 0.002, 'l2': 0.0, 'embedding_dim': 128, 'batch_size': 256}\n",
      "Test MRR 0.3365693739267653 val MRR 0.34586494022424175\n",
      "Evaluating {'num_negative_samples': 100, 'n_iter': 90, 'loss': 'adaptive_hinge', 'learning_rate': 0.002, 'l2': 0.0, 'embedding_dim': 128, 'batch_size': 256}\n",
      "Test MRR 0.3416527568905696 val MRR 0.3504815809619977\n",
      "Evaluating {'num_negative_samples': 15, 'n_iter': 50, 'loss': 'adaptive_hinge', 'learning_rate': 0.002, 'l2': 0.0, 'embedding_dim': 256, 'batch_size': 256}\n",
      "Test MRR 0.3185451469048775 val MRR 0.3345254757436679\n",
      "Evaluating {'num_negative_samples': 30, 'n_iter': 50, 'loss': 'adaptive_hinge', 'learning_rate': 0.002, 'l2': 0.0, 'embedding_dim': 256, 'batch_size': 256}\n",
      "Test MRR 0.33490785013648866 val MRR 0.3524765537562136\n",
      "Evaluating {'num_negative_samples': 60, 'n_iter': 50, 'loss': 'adaptive_hinge', 'learning_rate': 0.002, 'l2': 0.0, 'embedding_dim': 256, 'batch_size': 256}\n",
      "Test MRR 0.34003492369369975 val MRR 0.3485027800645095\n",
      "Evaluating {'num_negative_samples': 100, 'n_iter': 50, 'loss': 'adaptive_hinge', 'learning_rate': 0.002, 'l2': 0.0, 'embedding_dim': 256, 'batch_size': 256}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Stuff\\booking_wisdom\\spotlight_hyperparams_movielens_sequence.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(train, test, validation, random_state, model_type)\u001b[0m\n\u001b[0;32m    278\u001b[0m                                        \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m                                        \u001b[0mvalidation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m                                        random_state)\n\u001b[0m\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         print('Test MRR {} val MRR {}'.format(\n",
      "\u001b[1;32m~\\Desktop\\Stuff\\booking_wisdom\\spotlight_hyperparams_movielens_sequence.py\u001b[0m in \u001b[0;36mevaluate_lstm_model\u001b[1;34m(hyperparameters, train, test, validation, random_state)\u001b[0m\n\u001b[0;32m    217\u001b[0m                                   )\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[0mtest_mrr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msequence_mrr_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\spotlight\\sequence\\implicit.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, interactions, verbose)\u001b[0m\n\u001b[0;32m    251\u001b[0m                 \u001b[0mepoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \"\"\"\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run(train, test, validation, random_state, \"lstm\")\n",
    "\n",
    "# Best lstm result: {'test_mrr': 0.2304, 'validation_mrr': 0.256,\n",
    "# 'n_iter': 5, 'loss': 'adaptive_hinge', 'learning_rate': 0.05, 'l2': 0.0001, 'embedding_dim': 64, 'batch_size': 512}\n",
    "\n",
    "\n",
    "# Evaluating {'n_iter': 20, 'loss': 'adaptive_hinge', 'learning_rate': 0.01, 'l2': 0.0001, 'embedding_dim': 128, 'batch_size': 128}\n",
    "# Test MRR 0.269 val MRR 0.2738\\\n",
    "\n",
    "\n",
    "# {'n_iter': 40, 'loss': 'adaptive_hinge', 'learning_rate': 0.002, 'l2': 1e-08, 'embedding_dim': 128, 'batch_size': 128}\n",
    "# Test MRR 0.2826 val MRR 0.2798\n",
    "\n",
    "\n",
    "\n",
    "# ### less data samples :\n",
    "# Evaluating {'num_negative_samples': 10, 'n_iter': 50, 'loss': 'adaptive_hinge', 'learning_rate': 0.005, 'l2': 0.0, 'embedding_dim': 256, 'batch_size': 128}\n",
    "# Test MRR 0.306 val MRR 0.311\n",
    "\n",
    "# Evaluating {'num_negative_samples': 10, 'n_iter': 50, 'loss': 'adaptive_hinge', 'learning_rate': 0.001, 'l2': 0.0, 'embedding_dim': 128, 'batch_size': 128}\n",
    "# Test MRR 0.3078 val MRR 0.308\n",
    "\n",
    "\n",
    "## another orund, smallishj samploes \n",
    "# Evaluating {'num_negative_samples': 20, 'n_iter': 50, 'loss': 'adaptive_hinge', 'learning_rate': 0.002, 'l2': 0.0, 'embedding_dim': 256, 'batch_size': 256}\n",
    "# Test MRR 0.330 val MRR 0.32771"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# run(train, test, validation, random_state, model_type=\"pooling\")\n",
    "\n",
    "# # Best pooling result: {'test_mrr': 0.28493, 'validation_mrr': 0.222,\n",
    "# # 'n_iter': 15, 'loss': 'hinge', 'learning_rate': 0.01, 'l2': 0.0, 'embedding_dim': 64, 'batch_size': 16}\n",
    "\n",
    "# Best pooling result: {'test_mrr': 0.2849, 'validation_mrr': 0.22,\n",
    "#                       'n_iter': 15, 'loss': 'hinge', 'learning_rate': 0.01, 'l2': 0.0, 'embedding_dim': 64, 'batch_size': 16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
