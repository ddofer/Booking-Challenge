{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LibRecommender models experiments\n",
    "\n",
    "* https://github.com/massquantity/LibRecommender/tree/master/examples\n",
    "\n",
    "* Try different models. \n",
    "* Note that we explicitly create negatives.\n",
    "* Can do train test split by time or other things\n",
    "\n",
    "\n",
    "* Data Format\n",
    "    * One thing is important, the model assumes that user, item, and label column index are 0, 1, and 2, respectively. You may wish to change the column order if that's not the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible approahc + negatives - https://github.com/zhangruiskyline/DeepLearning/blob/master/doc/Recommendation.md#ranking \n",
    "\n",
    "\n",
    "* Negative sampling from the sparse user-item cooccurrence matrix\n",
    "    * https://stackoverflow.com/questions/49971318/how-to-generate-negative-samples-in-tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from catboost import CatBoostClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "import numpy as np\n",
    "import random\n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, GroupShuffleSplit\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.metrics import TopKCategoricalAccuracy, Precision, SparseTopKCategoricalAccuracy # @4\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from libreco.data import split_by_ratio_chrono, DatasetFeat, split_by_ratio\n",
    "from libreco.algorithms import (\n",
    "    FM, WideDeep, DeepFM, AutoInt, DIN, YouTubeMatch, YouTubeRanking\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_state(name):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    print(\"\\n\", \"=\" * 30, name, \"=\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: GeForce RTX 2060 (UUID: GPU-d8cefda9-d4cb-990c-cc01-a2a4f2416484)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.keras.layers.enable_v2_dtype_behavior()\n",
    "## https://www.tensorflow.org/guide/mixed_precision ## TF mixed precision - pytorch requires other setup\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)\n",
    "## will need to correct in places, e.g.: \n",
    "## outputs = layers.Activation('softmax', dtype='float32', name='predictions')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features to add:\n",
    "* Lag \n",
    "* Rank (popularity) of city, country (in general, +- given booker country)\n",
    "* Count of hotel; user, trip size ? (may be leaky )\n",
    "* Seasonal features - Holidays? , datetime\n",
    "\n",
    "Aggregate feats:\n",
    "* user changed country? last booking (lag 1) country change? \n",
    "* max/min/avg popularity rank of previous locations visited\n",
    "\n",
    "\n",
    "\n",
    "We should create a dictionary of the rank, count, city/country etc' feats, so we can easily merge them when making more \"negative\" samples/feats for ranking.\n",
    "\n",
    "\n",
    "* Consider using a df2 of df without dates + drop_duplicates, +- without user/trip id (After calcing that) .\n",
    "\n",
    "\n",
    "Leaky or potentially leaky (Dependso n test set): \n",
    "* Target freq features - frequency of target city, given source county +- affiliate +- month of year +- given country (and interactions of target freq). \n",
    "    * Risk of leaks - depends of test data has temporal split or not. \n",
    "    * cartboost can do target encode, but this lets us do it for interactions, e.g. target city freq given the 2 countries and affiliate.\n",
    "    * beware overfitting! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_TARGET_FREQ = 25 # drop target/city_id values that appear less than this many times, as final step's target \n",
    "KEEP_TOP_K_TARGETS = 0 # keep K most frequent city ID targets (redundnat with the above, )\n",
    "\n",
    "## (some) categorical variables that appear less than this many times will be replaced with a placeholder value!\n",
    "## Includes CITY id (but done after target filtering, to avoid creating a \"rare class\" target:\n",
    "LOW_COUNT_THRESH = 10\n",
    "\n",
    "RUN_TABNET = False\n",
    "max_epochs = 20\n",
    "\n",
    "GET_COUNT_AGG_FEATS = False ## disable getting count, rank etc' groupby features , for speedup\n",
    "\n",
    "DROP_FIRST_ROW =  True #False  ## drop first interaction per user from train data\n",
    "\n",
    "## for matrix factorization/CF:\n",
    "### morte possible ID_cols :  # last (last step in trip) - would double data per user incorrectly\n",
    "### hotel_country_lag1 , city_id_lag1  (very relevant - needs shared embeddingm and would increase cardinality a lot.. ) \n",
    "ID_COLS = [\n",
    "#     'device_class',\n",
    "#            'affiliate_id',\n",
    "           'booker_country',\n",
    "           'checkin_quarter',\n",
    "#            \"last\",\n",
    "          \"first_hotel_country\"] \n",
    "MF_KEEP_COLS = [\"ID\"]+ID_COLS+['city_id',\"hotel_country\"]\n",
    "\n",
    "SAVE_TO_DISK = False\n",
    "\n",
    "TARGET_COL =  'city_id' #\"city_id\"#'hotel_country' \n",
    "USER_ID_COL = \"utrip_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most basic categorical columns , without 'user_id', , 'utrip_id' ordevice_class - used for count encoding/filtering\n",
    "BASE_CAT_COLS = ['city_id',  'affiliate_id', 'booker_country', 'hotel_country']\n",
    "\n",
    "# ### features to get lags for. Not very robust. May want different feats for lags before -1\n",
    "# LAG_FEAT_COLS = ['city_id', 'device_class',\n",
    "#        'affiliate_id', 'booker_country', 'hotel_country', \n",
    "#        'duration', 'same_country', 'checkin_day', 'checkin_weekday',\n",
    "#        'checkin_week',\n",
    "#         'checkout_weekday','checkout_week',\n",
    "#        'city_id_count', 'affiliate_id_count',\n",
    "#        'booker_country_count', 'hotel_country_count', \n",
    "#        'checkin_month_count', 'checkin_week_count', 'city_id_nunique',\n",
    "#        'affiliate_id_nunique', 'booker_country_nunique',\n",
    "#        'hotel_country_nunique', 'city_id_rank_by_hotel_country',\n",
    "#        'city_id_rank_by_booker_country', 'city_id_rank_by_affiliate',\n",
    "#        'affiliate_id_rank_by_hotel_country',\n",
    "#        'affiliate_id_rank_by_booker_country', 'affiliate_id_rank_by_affiliate',\n",
    "#        'booker_country_rank_by_hotel_country',\n",
    "#        'booker_country_rank_by_booker_country',\n",
    "#        'booker_country_rank_by_affiliate',\n",
    "#        'hotel_country_rank_by_hotel_country',\n",
    "#        'hotel_country_rank_by_booker_country',\n",
    "#        'hotel_country_rank_by_affiliate',\n",
    "#        'checkin_month_rank_by_hotel_country',\n",
    "#        'checkin_month_rank_by_booker_country',\n",
    "#        'checkin_month_rank_by_affiliate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/33907537/groupby-and-lag-all-columns-of-a-dataframe\n",
    "# https://stackoverflow.com/questions/62924987/lag-multiple-variables-grouped-by-columns\n",
    "## lag features with groupby over many columns: \n",
    "def groupbyLagFeatures(df:pd.DataFrame,lag:[]=[1,2],group=\"utrip_id\",lag_feature_cols=[]):\n",
    "    \"\"\"\n",
    "    lag features with groupby over many columns.\n",
    "    Assumes sorted data!\n",
    "    https://stackoverflow.com/questions/62924987/lag-multiple-variables-grouped-by-columns\"\"\"\n",
    "    if len(lag_feature_cols)>0:\n",
    "        df=pd.concat([df]+[df.groupby(group)[lag_feature_cols].shift(x).add_prefix('lag'+str(x)+\"_\") for x in lag],axis=1)\n",
    "    else:\n",
    "         df=pd.concat([df]+[df.groupby(group).shift(x).add_prefix('lag'+str(x)+\"_\") for x in lag],axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def groupbyFirstLagFeatures(df:pd.DataFrame,group=\"user_id\",lag_feature_cols=[]):\n",
    "    \"\"\"\n",
    "    Get  first/head value lag-like of features with groupby over columns. Assumes sorted data!\n",
    "    \"\"\"\n",
    "    if len(lag_feature_cols)>0:\n",
    "        df=pd.concat([df]+[df.groupby(group)[lag_feature_cols].transform(\"first\").add_prefix(\"first_\")],axis=1)\n",
    "    else:\n",
    "#          df=pd.concat([df]+[df.groupby(group).first().add_prefix(\"first_\")],axis=1)\n",
    "        df=pd.concat([df]+[df.groupby(group).transform(\"first\").add_prefix(\"first_\")],axis=1)\n",
    "    return df\n",
    "\n",
    "######## Get n most popular items, per group\n",
    "def most_popular(group, n_max=4):\n",
    "    \"\"\"Find most popular hotel clusters by destination\n",
    "    Define a function to get most popular hotels for a destination group.\n",
    "\n",
    "    Previous version used nlargest() Series method to get indices of largest elements. But the method is rather slow.\n",
    "    Source: https://www.kaggle.com/dvasyukova/predict-hotel-type-with-pandas\n",
    "    \"\"\"\n",
    "    relevance = group['relevance'].values\n",
    "    hotel_cluster = group['hotel_cluster'].values\n",
    "    most_popular = hotel_cluster[np.argsort(relevance)[::-1]][:n_max]\n",
    "    return np.array_str(most_popular)[1:-1] # remove square brackets\n",
    "\n",
    "\n",
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=64,target_col=\"target\"):\n",
    "    \"\"\"\n",
    "    Wrap dataframes with tf.data. \n",
    "    This will enable us to use feature columns as a bridge to map from the columns in a dataframe to features used to train the model.\n",
    "    https://www.tensorflow.org/tutorials/structured_data/feature_columns#create_an_input_pipeline_using_tfdata\n",
    "    \"\"\"\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(target_col)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds\n",
    "\n",
    "\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id           200153\n",
      "checkin              425\n",
      "checkout             425\n",
      "city_id            39901\n",
      "device_class           3\n",
      "affiliate_id        3254\n",
      "booker_country         5\n",
      "hotel_country        195\n",
      "utrip_id          217686\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>checkin</th>\n",
       "      <th>checkout</th>\n",
       "      <th>city_id</th>\n",
       "      <th>device_class</th>\n",
       "      <th>affiliate_id</th>\n",
       "      <th>booker_country</th>\n",
       "      <th>hotel_country</th>\n",
       "      <th>utrip_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>519017</th>\n",
       "      <td>727105</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>18820</td>\n",
       "      <td>mobile</td>\n",
       "      <td>359</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>Cobra Island</td>\n",
       "      <td>727105_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986596</th>\n",
       "      <td>2000964</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>63341</td>\n",
       "      <td>mobile</td>\n",
       "      <td>8151</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>Cobra Island</td>\n",
       "      <td>2000964_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7504</th>\n",
       "      <td>2595109</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>27404</td>\n",
       "      <td>mobile</td>\n",
       "      <td>359</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>Cobra Island</td>\n",
       "      <td>2595109_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52884</th>\n",
       "      <td>110418</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>3763</td>\n",
       "      <td>desktop</td>\n",
       "      <td>9924</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>Glubbdubdrib</td>\n",
       "      <td>110418_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068508</th>\n",
       "      <td>221863</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>45597</td>\n",
       "      <td>mobile</td>\n",
       "      <td>7774</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>221863_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908844</th>\n",
       "      <td>5755992</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>52860</td>\n",
       "      <td>desktop</td>\n",
       "      <td>4568</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Axphain</td>\n",
       "      <td>5755992_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154024</th>\n",
       "      <td>5842454</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>35850</td>\n",
       "      <td>desktop</td>\n",
       "      <td>384</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Rook Islands</td>\n",
       "      <td>5842454_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160065</th>\n",
       "      <td>5936647</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>20199</td>\n",
       "      <td>desktop</td>\n",
       "      <td>4541</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Kasnia</td>\n",
       "      <td>5936647_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244942</th>\n",
       "      <td>5955565</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>54384</td>\n",
       "      <td>desktop</td>\n",
       "      <td>8132</td>\n",
       "      <td>Elbonia</td>\n",
       "      <td>Patusan</td>\n",
       "      <td>5955565_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787249</th>\n",
       "      <td>6172320</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>6005</td>\n",
       "      <td>mobile</td>\n",
       "      <td>9452</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>Patusan</td>\n",
       "      <td>6172320_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1166835 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id    checkin    checkout  city_id device_class  affiliate_id  \\\n",
       "519017    727105 2015-12-31  2016-01-01    18820       mobile           359   \n",
       "986596   2000964 2015-12-31  2016-01-01    63341       mobile          8151   \n",
       "7504     2595109 2015-12-31  2016-01-01    27404       mobile           359   \n",
       "52884     110418 2016-01-01  2016-01-02     3763      desktop          9924   \n",
       "1068508   221863 2016-01-01  2016-01-02    45597       mobile          7774   \n",
       "...          ...        ...         ...      ...          ...           ...   \n",
       "908844   5755992 2017-02-27  2017-02-28    52860      desktop          4568   \n",
       "1154024  5842454 2017-02-27  2017-02-28    35850      desktop           384   \n",
       "1160065  5936647 2017-02-27  2017-02-28    20199      desktop          4541   \n",
       "244942   5955565 2017-02-27  2017-02-28    54384      desktop          8132   \n",
       "787249   6172320 2017-02-27  2017-02-28     6005       mobile          9452   \n",
       "\n",
       "               booker_country hotel_country   utrip_id  \n",
       "519017   The Devilfire Empire  Cobra Island   727105_1  \n",
       "986596   The Devilfire Empire  Cobra Island  2000964_1  \n",
       "7504     The Devilfire Empire  Cobra Island  2595109_1  \n",
       "52884    The Devilfire Empire  Glubbdubdrib   110418_1  \n",
       "1068508                Gondal        Gondal   221863_1  \n",
       "...                       ...           ...        ...  \n",
       "908844                 Gondal       Axphain  5755992_4  \n",
       "1154024                Gondal  Rook Islands  5842454_6  \n",
       "1160065                Gondal        Kasnia  5936647_2  \n",
       "244942                Elbonia       Patusan  5955565_2  \n",
       "787249   The Devilfire Empire       Patusan  6172320_1  \n",
       "\n",
       "[1166835 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"booking_train_set.csv\",\n",
    "#                  nrows=323456,\n",
    "                 index_col=[0],\n",
    "                 parse_dates=[\"checkin\"],infer_datetime_format=True)\n",
    "\n",
    "df.sort_values([ \"checkin\",\n",
    "                \"user_id\"],inplace=True)\n",
    "print(df.nunique())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### i disabled most of thefeature eztraction here for simplicity\n",
    "\n",
    "# df[\"duration\"] = (df[\"checkout\"] - df[\"checkin\"]).dt.days\n",
    "# df[\"same_country\"] = (df[\"booker_country\"]==df[\"hotel_country\"]).astype(int)\n",
    "\n",
    "# df[\"checkin_day\"] = df[\"checkin\"].dt.day\n",
    "# df[\"checkin_weekday\"] = df[\"checkin\"].dt.weekday\n",
    "df[\"checkin_week\"] = df[\"checkin\"].dt.isocalendar().week.astype(int) ## week of year\n",
    "df[\"checkin_month\"] = df[\"checkin\"].dt.month\n",
    "# df[\"checkin_year\"] = df[\"checkin\"].dt.year-2016\n",
    "\n",
    "df[\"checkin_quarter\"] = df[\"checkin\"].dt.quarter # relatively redundant but may be used for \"id\"\n",
    "\n",
    "# df[\"checkin_quarter\"] = df[\"checkin_quarter\"]/4 # scale. could also do cos, sin extraction. makesi t a float instead of int/embedding\n",
    "\n",
    "\n",
    "# df[\"checkout_weekday\"] = df[\"checkout\"].dt.weekday\n",
    "# df[\"checkout_week\"] = df[\"checkout\"].dt.isocalendar().week.astype(int) ## week of year\n",
    "# df[\"checkout_day\"] = df[\"checkout\"].dt.day ## day of month\n",
    "\n",
    "## cyclical datetime embeddings\n",
    "## drop originakl variables? \n",
    "## TODO:L add for other variables, +- those that we'll embed (week?)\n",
    "\n",
    "# df['checkin_weekday_sin'] = np.sin(df[\"checkin_weekday\"]*(2.*np.pi/7))\n",
    "# df['checkin_weekday_cos'] = np.cos(df[\"checkin_weekday\"]*(2.*np.pi/7))\n",
    "# df['checkin_month_sin'] = np.sin((df[\"checkin_month\"]-1)*(2.*np.pi/12))\n",
    "# df['checkin_month_cos'] = np.cos((df[\"checkin_month\"]-1)*(2.*np.pi/12))\n",
    "\n",
    "# #############\n",
    "# # last number in utrip id - probably which trip number it is:\n",
    "# df[\"utrip_number\"] = df[\"utrip_id\"].str.split(\"_\",expand=True)[1].astype(int)\n",
    "\n",
    "### encode string columns - must be consistent with test data \n",
    "### IF we can concat test with train, we can just do a single transformation  for the NON TARGET cols\n",
    "# obj_cols_list = df.select_dtypes(\"O\").columns.values\n",
    "obj_cols_list = ['device_class','booker_country','hotel_country',\n",
    "#                 \"city_id\"\n",
    "                ] # we could also define when loading data, dtype\n",
    "\n",
    "for c in obj_cols_list:\n",
    "    df[c] = df[c].astype(\"category\")\n",
    "#     df[c] = df[c].cat.codes.astype(int)\n",
    "#     print(\"min\",df[c].min()) min is 0 - which is what the embedding (indices) will expect\n",
    "\n",
    "## view steps of a trip per user & trip, in order. ## last step == 1.\n",
    "## count #/pct step in a trip (utrip_id) per user. Useful to get the \"final\" step per trip - for prediction\n",
    "## note that the order is ascending, so we would need to select by \"last\" . (i.e \"1\" is the first step, 2 the second, etc') , or we could use pct .rank(ascending=True,pct=True)\n",
    "#### this feature overlaps with the count of each trip id (for the final row)\n",
    "##  = df.sort_values([\"checkin\",\"checkout\"])... - df already sorted above\n",
    "# df[\"utrip_steps_from_end\"] = df.groupby(\"utrip_id\")[\"checkin\"].rank(ascending=True,pct=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### add features to be consistent with test set of row in trip, and total trips in trip\n",
    "\n",
    "df[\"row_num\"] = df.groupby(\"utrip_id\")[\"checkin\"].rank(ascending=True,pct=False).astype(int)\n",
    "utrip_counts = df[\"utrip_id\"].value_counts()\n",
    "df[\"total_rows\"] = df[\"utrip_id\"].map(utrip_counts)\n",
    "\n",
    "### last step in trip\n",
    "df[\"last\"] = (df[\"total_rows\"]==df[\"row_num\"]).astype(int)\n",
    "\n",
    "df[\"total_rows\"].describe();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### replace rare categorical variable(s) - affiliates\n",
    "* replace rare variables (under 2 occurrences) with \"-1\" dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: 9924     277775\n",
      "359      171385\n",
      "384       88137\n",
      "9452      85476\n",
      "4541      41504\n",
      "          ...  \n",
      "8351          1\n",
      "8464          1\n",
      "2202          1\n",
      "10513         1\n",
      "2047          1\n",
      "Name: affiliate_id, Length: 3254, dtype: int64\n",
      "uniques 3254\n",
      "after\n",
      " 9924    277775\n",
      "359     171385\n",
      "384      88137\n",
      "9452     85476\n",
      "4541     41504\n",
      "         ...  \n",
      "2615         3\n",
      "5963         3\n",
      "2618         3\n",
      "838          3\n",
      "176          3\n",
      "Name: affiliate_id, Length: 2152, dtype: int64\n",
      "uniques 2152\n"
     ]
    }
   ],
   "source": [
    "### replace rare variables (under 2 occurrences) with \"-1\" dummy\n",
    "\n",
    "affiliates_counts = df[\"affiliate_id\"].value_counts()\n",
    "print(\"before:\", affiliates_counts)\n",
    "print(\"uniques\",df[\"affiliate_id\"].nunique())\n",
    "affiliates_counts = affiliates_counts.to_dict()\n",
    "# df[\"affiliate_id\"] = df[\"affiliate_id\"].where(df[\"affiliate_id\"].apply(lambda x: x.map(x.value_counts()))>=3, -1)\n",
    "df[\"affiliate_id\"] = df[\"affiliate_id\"].where(df[\"affiliate_id\"].map(affiliates_counts)>=3, -2)\n",
    "df[\"affiliate_id\"] = df[\"affiliate_id\"].astype(int)\n",
    "\n",
    "print(\"after\\n\",df[\"affiliate_id\"].value_counts())\n",
    "print(\"uniques\",df[\"affiliate_id\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"total_rows\"].map(pd.cut(df[\"total_rows\"],bins=3,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add LAG feature(s)  + DROP First visited location rows\n",
    "* \"first\" hotel country (vs most recent country visited)\n",
    "    * `groupbyFirstLagFeatures(df,group=\"user_id\",lag_feature_cols=[\"hotel_country\",\"city_id\"])`\n",
    "* Can consider: lag1 hotel_country, hotel_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_hotel_country      144\n",
      "hotel_country            195\n",
      "city_id                39901\n",
      "first_city_id           7863\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>checkin</th>\n",
       "      <th>checkout</th>\n",
       "      <th>city_id</th>\n",
       "      <th>device_class</th>\n",
       "      <th>affiliate_id</th>\n",
       "      <th>booker_country</th>\n",
       "      <th>hotel_country</th>\n",
       "      <th>utrip_id</th>\n",
       "      <th>checkin_week</th>\n",
       "      <th>checkin_month</th>\n",
       "      <th>checkin_quarter</th>\n",
       "      <th>row_num</th>\n",
       "      <th>total_rows</th>\n",
       "      <th>last</th>\n",
       "      <th>first_hotel_country</th>\n",
       "      <th>first_city_id</th>\n",
       "      <th>first_device_class</th>\n",
       "      <th>first_affiliate_id</th>\n",
       "      <th>first_checkin_quarter</th>\n",
       "      <th>first_checkin_month</th>\n",
       "      <th>first_booker_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>519017</th>\n",
       "      <td>727105</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>18820</td>\n",
       "      <td>mobile</td>\n",
       "      <td>359</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>Cobra Island</td>\n",
       "      <td>727105_1</td>\n",
       "      <td>53</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Cobra Island</td>\n",
       "      <td>18820</td>\n",
       "      <td>mobile</td>\n",
       "      <td>359</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986596</th>\n",
       "      <td>2000964</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>63341</td>\n",
       "      <td>mobile</td>\n",
       "      <td>8151</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>Cobra Island</td>\n",
       "      <td>2000964_1</td>\n",
       "      <td>53</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Cobra Island</td>\n",
       "      <td>63341</td>\n",
       "      <td>mobile</td>\n",
       "      <td>8151</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7504</th>\n",
       "      <td>2595109</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>27404</td>\n",
       "      <td>mobile</td>\n",
       "      <td>359</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>Cobra Island</td>\n",
       "      <td>2595109_1</td>\n",
       "      <td>53</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Cobra Island</td>\n",
       "      <td>18820</td>\n",
       "      <td>mobile</td>\n",
       "      <td>359</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52884</th>\n",
       "      <td>110418</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>3763</td>\n",
       "      <td>desktop</td>\n",
       "      <td>9924</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>Glubbdubdrib</td>\n",
       "      <td>110418_1</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Glubbdubdrib</td>\n",
       "      <td>3763</td>\n",
       "      <td>desktop</td>\n",
       "      <td>9924</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068508</th>\n",
       "      <td>221863</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>45597</td>\n",
       "      <td>mobile</td>\n",
       "      <td>7774</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>221863_1</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>45597</td>\n",
       "      <td>mobile</td>\n",
       "      <td>7774</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Gondal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908844</th>\n",
       "      <td>5755992</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>52860</td>\n",
       "      <td>desktop</td>\n",
       "      <td>4568</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Axphain</td>\n",
       "      <td>5755992_4</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>29394</td>\n",
       "      <td>desktop</td>\n",
       "      <td>4568</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Gondal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154024</th>\n",
       "      <td>5842454</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>35850</td>\n",
       "      <td>desktop</td>\n",
       "      <td>384</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Rook Islands</td>\n",
       "      <td>5842454_6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Sylvania</td>\n",
       "      <td>14342</td>\n",
       "      <td>desktop</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Gondal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160065</th>\n",
       "      <td>5936647</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>20199</td>\n",
       "      <td>desktop</td>\n",
       "      <td>4541</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Kasnia</td>\n",
       "      <td>5936647_2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Rolisica</td>\n",
       "      <td>8462</td>\n",
       "      <td>desktop</td>\n",
       "      <td>4541</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Gondal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244942</th>\n",
       "      <td>5955565</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>54384</td>\n",
       "      <td>desktop</td>\n",
       "      <td>8132</td>\n",
       "      <td>Elbonia</td>\n",
       "      <td>Patusan</td>\n",
       "      <td>5955565_2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Elbonia</td>\n",
       "      <td>52327</td>\n",
       "      <td>desktop</td>\n",
       "      <td>8132</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Elbonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787249</th>\n",
       "      <td>6172320</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>6005</td>\n",
       "      <td>mobile</td>\n",
       "      <td>9452</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>Patusan</td>\n",
       "      <td>6172320_1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Sokovia</td>\n",
       "      <td>34342</td>\n",
       "      <td>mobile</td>\n",
       "      <td>9452</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1166835 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id    checkin    checkout  city_id device_class  affiliate_id  \\\n",
       "519017    727105 2015-12-31  2016-01-01    18820       mobile           359   \n",
       "986596   2000964 2015-12-31  2016-01-01    63341       mobile          8151   \n",
       "7504     2595109 2015-12-31  2016-01-01    27404       mobile           359   \n",
       "52884     110418 2016-01-01  2016-01-02     3763      desktop          9924   \n",
       "1068508   221863 2016-01-01  2016-01-02    45597       mobile          7774   \n",
       "...          ...        ...         ...      ...          ...           ...   \n",
       "908844   5755992 2017-02-27  2017-02-28    52860      desktop          4568   \n",
       "1154024  5842454 2017-02-27  2017-02-28    35850      desktop           384   \n",
       "1160065  5936647 2017-02-27  2017-02-28    20199      desktop          4541   \n",
       "244942   5955565 2017-02-27  2017-02-28    54384      desktop          8132   \n",
       "787249   6172320 2017-02-27  2017-02-28     6005       mobile          9452   \n",
       "\n",
       "               booker_country hotel_country   utrip_id  checkin_week  \\\n",
       "519017   The Devilfire Empire  Cobra Island   727105_1            53   \n",
       "986596   The Devilfire Empire  Cobra Island  2000964_1            53   \n",
       "7504     The Devilfire Empire  Cobra Island  2595109_1            53   \n",
       "52884    The Devilfire Empire  Glubbdubdrib   110418_1            53   \n",
       "1068508                Gondal        Gondal   221863_1            53   \n",
       "...                       ...           ...        ...           ...   \n",
       "908844                 Gondal       Axphain  5755992_4             9   \n",
       "1154024                Gondal  Rook Islands  5842454_6             9   \n",
       "1160065                Gondal        Kasnia  5936647_2             9   \n",
       "244942                Elbonia       Patusan  5955565_2             9   \n",
       "787249   The Devilfire Empire       Patusan  6172320_1             9   \n",
       "\n",
       "         checkin_month  checkin_quarter  row_num  total_rows  last  \\\n",
       "519017              12                4        1           4     0   \n",
       "986596              12                4        1           5     0   \n",
       "7504                12                4        1           4     0   \n",
       "52884                1                1        1          10     0   \n",
       "1068508              1                1        1           8     0   \n",
       "...                ...              ...      ...         ...   ...   \n",
       "908844               2                1        5           5     1   \n",
       "1154024              2                1        9           9     1   \n",
       "1160065              2                1       12          12     1   \n",
       "244942               2                1        5           5     1   \n",
       "787249               2                1       10          10     1   \n",
       "\n",
       "        first_hotel_country  first_city_id first_device_class  \\\n",
       "519017         Cobra Island          18820             mobile   \n",
       "986596         Cobra Island          63341             mobile   \n",
       "7504           Cobra Island          18820             mobile   \n",
       "52884          Glubbdubdrib           3763            desktop   \n",
       "1068508              Gondal          45597             mobile   \n",
       "...                     ...            ...                ...   \n",
       "908844               Gondal          29394            desktop   \n",
       "1154024            Sylvania          14342            desktop   \n",
       "1160065            Rolisica           8462            desktop   \n",
       "244942              Elbonia          52327            desktop   \n",
       "787249              Sokovia          34342             mobile   \n",
       "\n",
       "         first_affiliate_id  first_checkin_quarter  first_checkin_month  \\\n",
       "519017                  359                      4                   12   \n",
       "986596                 8151                      4                   12   \n",
       "7504                    359                      4                   12   \n",
       "52884                  9924                      1                    1   \n",
       "1068508                7774                      1                    1   \n",
       "...                     ...                    ...                  ...   \n",
       "908844                 4568                      1                    2   \n",
       "1154024                 384                      1                    2   \n",
       "1160065                4541                      1                    2   \n",
       "244942                 8132                      1                    2   \n",
       "787249                 9452                      1                    2   \n",
       "\n",
       "         first_booker_country  \n",
       "519017   The Devilfire Empire  \n",
       "986596   The Devilfire Empire  \n",
       "7504     The Devilfire Empire  \n",
       "52884    The Devilfire Empire  \n",
       "1068508                Gondal  \n",
       "...                       ...  \n",
       "908844                 Gondal  \n",
       "1154024                Gondal  \n",
       "1160065                Gondal  \n",
       "244942                Elbonia  \n",
       "787249   The Devilfire Empire  \n",
       "\n",
       "[1166835 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## add the \"first\" place visited/values\n",
    "### nopte - will need to drop first row in trip, or impute nans when using this feature \n",
    "\n",
    "### first by user results in too much sparsity/rareness for our IDs purposes\n",
    "# df = groupbyFirstLagFeatures(df,group=\"user_id\",lag_feature_cols=[\"hotel_country\"]) # [\"hotel_country\",\"city_id\"]\n",
    "\n",
    "## alt - messy, but maybe good enough : \n",
    "df = groupbyFirstLagFeatures(df,group=['device_class', 'affiliate_id',\n",
    "                                       'booker_country','checkin_month',\"last\"],\n",
    "                             lag_feature_cols=[\"hotel_country\",\"city_id\",'device_class', 'affiliate_id',\n",
    "                                              \"checkin_quarter\",\"checkin_month\",\"booker_country\"])\n",
    "\n",
    "\n",
    "print(df[[\"first_hotel_country\",\"hotel_country\",\"city_id\",\"first_city_id\"]].nunique())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                  200153\n",
       "checkin                     425\n",
       "checkout                    425\n",
       "city_id                   39901\n",
       "device_class                  3\n",
       "affiliate_id               2152\n",
       "booker_country                5\n",
       "hotel_country               195\n",
       "utrip_id                 217686\n",
       "checkin_week                 53\n",
       "checkin_month                12\n",
       "checkin_quarter               4\n",
       "row_num                      48\n",
       "total_rows                   41\n",
       "last                          2\n",
       "first_hotel_country         144\n",
       "first_city_id              7863\n",
       "first_device_class            3\n",
       "first_affiliate_id         2152\n",
       "first_checkin_quarter         4\n",
       "first_checkin_month          12\n",
       "first_booker_country          5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    39901.000000\n",
      "mean        29.243252\n",
      "std        218.801654\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          3.000000\n",
      "75%          9.000000\n",
      "max      11242.000000\n",
      "Name: city_id, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>checkin</th>\n",
       "      <th>checkout</th>\n",
       "      <th>city_id</th>\n",
       "      <th>device_class</th>\n",
       "      <th>affiliate_id</th>\n",
       "      <th>booker_country</th>\n",
       "      <th>hotel_country</th>\n",
       "      <th>utrip_id</th>\n",
       "      <th>checkin_week</th>\n",
       "      <th>checkin_month</th>\n",
       "      <th>checkin_quarter</th>\n",
       "      <th>row_num</th>\n",
       "      <th>total_rows</th>\n",
       "      <th>last</th>\n",
       "      <th>first_hotel_country</th>\n",
       "      <th>first_city_id</th>\n",
       "      <th>first_device_class</th>\n",
       "      <th>first_affiliate_id</th>\n",
       "      <th>first_checkin_quarter</th>\n",
       "      <th>first_checkin_month</th>\n",
       "      <th>first_booker_country</th>\n",
       "      <th>city_id_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>519017</th>\n",
       "      <td>727105</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>18820</td>\n",
       "      <td>mobile</td>\n",
       "      <td>359</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>Cobra Island</td>\n",
       "      <td>727105_1</td>\n",
       "      <td>53</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Cobra Island</td>\n",
       "      <td>18820</td>\n",
       "      <td>mobile</td>\n",
       "      <td>359</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986596</th>\n",
       "      <td>2000964</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>63341</td>\n",
       "      <td>mobile</td>\n",
       "      <td>8151</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>Cobra Island</td>\n",
       "      <td>2000964_1</td>\n",
       "      <td>53</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Cobra Island</td>\n",
       "      <td>63341</td>\n",
       "      <td>mobile</td>\n",
       "      <td>8151</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7504</th>\n",
       "      <td>2595109</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>27404</td>\n",
       "      <td>mobile</td>\n",
       "      <td>359</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>Cobra Island</td>\n",
       "      <td>2595109_1</td>\n",
       "      <td>53</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Cobra Island</td>\n",
       "      <td>18820</td>\n",
       "      <td>mobile</td>\n",
       "      <td>359</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>3614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52884</th>\n",
       "      <td>110418</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>3763</td>\n",
       "      <td>desktop</td>\n",
       "      <td>9924</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>Glubbdubdrib</td>\n",
       "      <td>110418_1</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Glubbdubdrib</td>\n",
       "      <td>3763</td>\n",
       "      <td>desktop</td>\n",
       "      <td>9924</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>5544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068508</th>\n",
       "      <td>221863</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>45597</td>\n",
       "      <td>mobile</td>\n",
       "      <td>7774</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>221863_1</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>45597</td>\n",
       "      <td>mobile</td>\n",
       "      <td>7774</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908844</th>\n",
       "      <td>5755992</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>52860</td>\n",
       "      <td>desktop</td>\n",
       "      <td>4568</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Axphain</td>\n",
       "      <td>5755992_4</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>29394</td>\n",
       "      <td>desktop</td>\n",
       "      <td>4568</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154024</th>\n",
       "      <td>5842454</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>35850</td>\n",
       "      <td>desktop</td>\n",
       "      <td>384</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Rook Islands</td>\n",
       "      <td>5842454_6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Sylvania</td>\n",
       "      <td>14342</td>\n",
       "      <td>desktop</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160065</th>\n",
       "      <td>5936647</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>20199</td>\n",
       "      <td>desktop</td>\n",
       "      <td>4541</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Kasnia</td>\n",
       "      <td>5936647_2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Rolisica</td>\n",
       "      <td>8462</td>\n",
       "      <td>desktop</td>\n",
       "      <td>4541</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244942</th>\n",
       "      <td>5955565</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>54384</td>\n",
       "      <td>desktop</td>\n",
       "      <td>8132</td>\n",
       "      <td>Elbonia</td>\n",
       "      <td>Patusan</td>\n",
       "      <td>5955565_2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Elbonia</td>\n",
       "      <td>52327</td>\n",
       "      <td>desktop</td>\n",
       "      <td>8132</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Elbonia</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787249</th>\n",
       "      <td>6172320</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>6005</td>\n",
       "      <td>mobile</td>\n",
       "      <td>9452</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>Patusan</td>\n",
       "      <td>6172320_1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Sokovia</td>\n",
       "      <td>34342</td>\n",
       "      <td>mobile</td>\n",
       "      <td>9452</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1166835 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id    checkin    checkout  city_id device_class  affiliate_id  \\\n",
       "519017    727105 2015-12-31  2016-01-01    18820       mobile           359   \n",
       "986596   2000964 2015-12-31  2016-01-01    63341       mobile          8151   \n",
       "7504     2595109 2015-12-31  2016-01-01    27404       mobile           359   \n",
       "52884     110418 2016-01-01  2016-01-02     3763      desktop          9924   \n",
       "1068508   221863 2016-01-01  2016-01-02    45597       mobile          7774   \n",
       "...          ...        ...         ...      ...          ...           ...   \n",
       "908844   5755992 2017-02-27  2017-02-28    52860      desktop          4568   \n",
       "1154024  5842454 2017-02-27  2017-02-28    35850      desktop           384   \n",
       "1160065  5936647 2017-02-27  2017-02-28    20199      desktop          4541   \n",
       "244942   5955565 2017-02-27  2017-02-28    54384      desktop          8132   \n",
       "787249   6172320 2017-02-27  2017-02-28     6005       mobile          9452   \n",
       "\n",
       "               booker_country hotel_country   utrip_id  checkin_week  \\\n",
       "519017   The Devilfire Empire  Cobra Island   727105_1            53   \n",
       "986596   The Devilfire Empire  Cobra Island  2000964_1            53   \n",
       "7504     The Devilfire Empire  Cobra Island  2595109_1            53   \n",
       "52884    The Devilfire Empire  Glubbdubdrib   110418_1            53   \n",
       "1068508                Gondal        Gondal   221863_1            53   \n",
       "...                       ...           ...        ...           ...   \n",
       "908844                 Gondal       Axphain  5755992_4             9   \n",
       "1154024                Gondal  Rook Islands  5842454_6             9   \n",
       "1160065                Gondal        Kasnia  5936647_2             9   \n",
       "244942                Elbonia       Patusan  5955565_2             9   \n",
       "787249   The Devilfire Empire       Patusan  6172320_1             9   \n",
       "\n",
       "         checkin_month  checkin_quarter  row_num  total_rows  last  \\\n",
       "519017              12                4        1           4     0   \n",
       "986596              12                4        1           5     0   \n",
       "7504                12                4        1           4     0   \n",
       "52884                1                1        1          10     0   \n",
       "1068508              1                1        1           8     0   \n",
       "...                ...              ...      ...         ...   ...   \n",
       "908844               2                1        5           5     1   \n",
       "1154024              2                1        9           9     1   \n",
       "1160065              2                1       12          12     1   \n",
       "244942               2                1        5           5     1   \n",
       "787249               2                1       10          10     1   \n",
       "\n",
       "        first_hotel_country  first_city_id first_device_class  \\\n",
       "519017         Cobra Island          18820             mobile   \n",
       "986596         Cobra Island          63341             mobile   \n",
       "7504           Cobra Island          18820             mobile   \n",
       "52884          Glubbdubdrib           3763            desktop   \n",
       "1068508              Gondal          45597             mobile   \n",
       "...                     ...            ...                ...   \n",
       "908844               Gondal          29394            desktop   \n",
       "1154024            Sylvania          14342            desktop   \n",
       "1160065            Rolisica           8462            desktop   \n",
       "244942              Elbonia          52327            desktop   \n",
       "787249              Sokovia          34342             mobile   \n",
       "\n",
       "         first_affiliate_id  first_checkin_quarter  first_checkin_month  \\\n",
       "519017                  359                      4                   12   \n",
       "986596                 8151                      4                   12   \n",
       "7504                    359                      4                   12   \n",
       "52884                  9924                      1                    1   \n",
       "1068508                7774                      1                    1   \n",
       "...                     ...                    ...                  ...   \n",
       "908844                 4568                      1                    2   \n",
       "1154024                 384                      1                    2   \n",
       "1160065                4541                      1                    2   \n",
       "244942                 8132                      1                    2   \n",
       "787249                 9452                      1                    2   \n",
       "\n",
       "         first_booker_country  city_id_count  \n",
       "519017   The Devilfire Empire            535  \n",
       "986596   The Devilfire Empire            196  \n",
       "7504     The Devilfire Empire           3614  \n",
       "52884    The Devilfire Empire           5544  \n",
       "1068508                Gondal            101  \n",
       "...                       ...            ...  \n",
       "908844                 Gondal             12  \n",
       "1154024                Gondal            692  \n",
       "1160065                Gondal             12  \n",
       "244942                Elbonia            526  \n",
       "787249   The Devilfire Empire            367  \n",
       "\n",
       "[1166835 rows x 23 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Following aggregation features - would be best to use time window (sort data) to generate, otherwise they will LEAK! (e.g. nunique countries visited)\n",
    "\n",
    "### count features (can also later add rank inside groups).\n",
    "### Some may be leaks (# visits in a trip should use time window?) , and do users repeat? \n",
    "### can add more counts of group X time period (e.g. affiliate X month of year)\n",
    "\n",
    "## alt way to get counts/freq :\n",
    "\n",
    "if GET_COUNT_AGG_FEATS:\n",
    "    count_cols = [ 'city_id','affiliate_id', 'booker_country', 'hotel_country', \n",
    "    #               'utrip_id','user_id', \n",
    "     \"checkin_month\",\"checkin_week\"]\n",
    "    for c in count_cols:\n",
    "        df[f\"{c}_count\"] = df.groupby([c])[\"duration\"].transform(\"size\")\n",
    "\n",
    "    ########################################################\n",
    "    ## nunique per trip\n",
    "    ### https://stackoverflow.com/questions/46470743/how-to-efficiently-compute-a-rolling-unique-count-in-a-pandas-time-series\n",
    "\n",
    "    nunique_cols = [ 'city_id','affiliate_id', 'booker_country', 'hotel_country']\n",
    "    # df[\"nunique_booker_countries\"] = df.groupby(\"utrip_id\")[\"booker_country\"].nunique()\n",
    "    # df[\"nunique_hotel_country\"] = df.groupby(\"utrip_id\")[\"hotel_country\"].nunique()\n",
    "    for c in nunique_cols:\n",
    "        df[f\"{c}_nunique\"] = df.groupby([\"utrip_id\"])[c].transform(\"nunique\")\n",
    "    print(df.nunique())\n",
    "\n",
    "    ########################################################\n",
    "    ## get frequency/count feature's rank within a group - e.g. within a country (or affiliate) \n",
    "    ## add \"_count\" to column name to get count col name, then add rank col \n",
    "\n",
    "    ### ALT/ duplicate feat - add percent rank (instead or in addition)\n",
    "\n",
    "    rank_cols = ['city_id','affiliate_id', 'booker_country','hotel_country',\n",
    "     \"checkin_month\"]\n",
    "    ### what is meaning of groupby and rank of smae variable by same var? Surely should be 1 / unary? \n",
    "    for c in rank_cols:\n",
    "        df[f\"{c}_rank_by_hotel_country\"] = df.groupby(['hotel_country'])[f\"{c}_count\"].transform(\"rank\")\n",
    "        df[f\"{c}_rank_by_booker_country\"] = df.groupby(['booker_country'])[f\"{c}_count\"].transform(\"rank\")\n",
    "        df[f\"{c}_rank_by_affiliate\"] = df.groupby(['affiliate_id'])[f\"{c}_count\"].transform(\"rank\")     \n",
    "else:\n",
    "    freq = df[\"city_id\"].value_counts()\n",
    "    df[\"city_id_count\"] = df[\"city_id\"].map(freq)\n",
    "    print(freq.describe())\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cities with more than 7 occurences: 12345\n",
      "cities with more than MIN_TARGET_FREQ (25) occurences: 4822\n",
      "rows left if filtering by MIN_TARGET_FREQ : 1010884\n"
     ]
    }
   ],
   "source": [
    "print(\"cities with more than 7 occurences:\",df.loc[df[\"city_id_count\"]>=7][\"city_id\"].nunique())\n",
    "print(f\"cities with more than MIN_TARGET_FREQ ({MIN_TARGET_FREQ}) occurences:\",df.loc[df[\"city_id_count\"]>=MIN_TARGET_FREQ][\"city_id\"].nunique())\n",
    "print(f\"rows left if filtering by MIN_TARGET_FREQ :\",df.loc[df[\"city_id_count\"]>=MIN_TARGET_FREQ].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df.isna().sum().max() ==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1029804\n",
      "df2 nunique (cities without duplicate user visits) 39901\n",
      "city counts\n",
      "23921    8137\n",
      "55128    7197\n",
      "47499    7188\n",
      "64876    6724\n",
      "29319    6361\n",
      "         ... \n",
      "50916       1\n",
      "57063       1\n",
      "46826       1\n",
      "38638       1\n",
      "2049        1\n",
      "Name: city_id, Length: 39901, dtype: int64\n",
      "count    39901.000000\n",
      "mean        25.808977\n",
      "std        173.750203\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          3.000000\n",
      "75%          9.000000\n",
      "max       8137.000000\n",
      "Name: city_id, dtype: float64\n",
      "cities with at least 2: 27533\n",
      "cities with at least 3: 21337\n",
      "cities with at least 5: 15248\n",
      "cities with at least 10: 9281\n",
      "cities with at least 15: 6836\n",
      "cities with at least 20: 5499\n",
      "cities with at least 30: 4006\n",
      "cities with at least 50: 2673\n",
      "cities with at least 100: 1550\n",
      "top 4 sum coverage (normalized):  0.028\n",
      "top 50 sum coverage (normalized):  0.183\n",
      "top 100 sum coverage (normalized):  0.263\n",
      "top 400 sum coverage (normalized):  0.481\n",
      "top 1,000 sum coverage (normalized):  0.64\n",
      "top 5,000 sum coverage (normalized):  0.858\n",
      "top 8,000 sum coverage (normalized):  0.905\n",
      "top 15,000 sum coverage (normalized):  0.955\n"
     ]
    }
   ],
   "source": [
    "# df2 = df[[\"user_id\",\"city_id\"]].drop_duplicates().copy()\n",
    "df2 = df.drop_duplicates(subset=[\"user_id\",\"city_id\"])[\"city_id\"].copy()\n",
    "print(df2.shape[0])\n",
    "print(\"df2 nunique (cities without duplicate user visits)\",df2.nunique())\n",
    "\n",
    "# c2_counts = df2[\"city_id\"].value_counts()\n",
    "c2_counts = df2.value_counts()\n",
    "# df2[\"new_counts\"] = df2[\"city_id\"].map(c2_counts)\n",
    "# df2[\"new_counts\"] = df2.map(c2_counts)\n",
    "print(\"city counts\")\n",
    "print(c2_counts)\n",
    "print(c2_counts.describe())\n",
    "print(\"cities with at least 2:\",(c2_counts>=2).sum())\n",
    "print(\"cities with at least 3:\",(c2_counts>=3).sum())\n",
    "print(\"cities with at least 5:\",(c2_counts>=5).sum())\n",
    "print(\"cities with at least 10:\",(c2_counts>=10).sum())\n",
    "print(\"cities with at least 15:\",(c2_counts>=15).sum())\n",
    "print(\"cities with at least 20:\",(c2_counts>=20).sum())\n",
    "print(\"cities with at least 30:\",(c2_counts>=30).sum())\n",
    "print(\"cities with at least 50:\",(c2_counts>=50).sum())\n",
    "print(\"cities with at least 100:\",(c2_counts>=100).sum())\n",
    "\n",
    "c2_freq = df2.value_counts(normalize=True)\n",
    "print(\"top 4 sum coverage (normalized): \",c2_freq[0:4].sum().round(3))\n",
    "print(\"top 50 sum coverage (normalized): \",c2_freq[0:50].sum().round(3))\n",
    "print(\"top 100 sum coverage (normalized): \",c2_freq[0:100].sum().round(3))\n",
    "print(\"top 400 sum coverage (normalized): \",c2_freq[0:400].sum().round(3))\n",
    "print(\"top 1,000 sum coverage (normalized): \",c2_freq[0:1000].sum().round(3))\n",
    "print(\"top 5,000 sum coverage (normalized): \",c2_freq[0:5000].sum().round(3))\n",
    "print(\"top 8,000 sum coverage (normalized): \",c2_freq[0:8000].sum().round(3))\n",
    "print(\"top 15,000 sum coverage (normalized): \",c2_freq[0:15000].sum().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequent city target List + City count encoding\n",
    "* Get the K most frequent target city IDs - selected based on frequency as final destination (not just overall)\n",
    "* +- Also after this, replace rare city IDs categorical features with count encoding to reduce dimensionality\n",
    "    * Keep them as count, or aggregate all of them as \"under_K\"?\n",
    "\n",
    "##### Output  : `TOP_TARGETS` - filter data by this *after* creation of lag features ! \n",
    "\n",
    "* Drop duplicates by the same user (reduce possible bias of frequent users? Only relevant if test is seperater from \"frequent travellers\") \n",
    "    * results in 216,633 , vs 217,686 without dropping duplicates by users\n",
    "    * ~19.9k unique cities\n",
    "    \n",
    "* Could do other encodings - https://contrib.scikit-learn.org/category_encoders/count.html\n",
    "\n",
    "* Note that all this is after we've added rank, count features beforehand, so that information won't be lost for these variables, despite these transforms\n",
    "\n",
    "\n",
    "\n",
    "* **NOTE** he most frequent final destinations are NOT the same as the most popular overall destinations +- first location ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if KEEP_TOP_K_TARGETS > 0 :\n",
    "    df_end = df.loc[df[\"utrip_steps_from_end\"]==1].drop_duplicates(subset=[\"city_id\",\"hotel_country\",\"user_id\"])[[\"city_id\",\"hotel_country\"]].copy()\n",
    "    print(df_end.shape[0])\n",
    "    end_city_counts = df_end.city_id.value_counts()\n",
    "    print(end_city_counts)\n",
    "    \n",
    "    TOP_TARGETS = end_city_counts.head(KEEP_TOP_K_TARGETS).index.values\n",
    "    print(f\"top {KEEP_TOP_K_TARGETS} targets \\n\",TOP_TARGETS)\n",
    "    \n",
    "#     assert df.loc[df[\"city_id\"].isin(TOP_TARGETS)][\"city_id\"].nunique() == KEEP_TOP_K_TARGETS\n",
    "\n",
    "####        \n",
    "# replace low frequency categoircal features    \n",
    "\n",
    "# ##replace with count encoding if have at least k, group rarest as \"-1\":# df[BASE_CAT_COLS] = df[BASE_CAT_COLS].where(df[BASE_CAT_COLS].apply(lambda x: x.map(x.value_counts()))>=LOW_COUNT_THRESH, -1)   \n",
    "# ## replace/group only the rare variables : \n",
    "# df[BASE_CAT_COLS] = df[BASE_CAT_COLS].where(df[BASE_CAT_COLS].apply(lambda x: x.map(x.value_counts()))>=LOW_COUNT_THRESH, -1)\n",
    "# df[BASE_CAT_COLS].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter data by city id frequency\n",
    "#### df2 - smaller df (may not ben ecessary to make\n",
    "\n",
    "* drop rows if it's city id appears less than X times - this is prior to CF\n",
    "* We could also add inclusion/exclusion based on target appearing/frequency as target in final stage of rtip - optional\n",
    "* maybe also drop (end exclude in freq counting) thefirst point in a trip ? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping users with less than 4 trips\n",
      "dropping cities with less than 25 occurences:\n",
      "1008673\n",
      "dropping users with less than 4 instances, after previous filters:\n",
      "rows left: 857829\n",
      "nunique cities after freq filt city_id            3667\n",
      "utrip_id         162904\n",
      "user_id          152608\n",
      "hotel_country       105\n",
      "dtype: int64\n",
      "nunique city_id per hotel_country:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    195.000000\n",
       "mean      18.805128\n",
       "std       54.053457\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        1.000000\n",
       "75%       11.500000\n",
       "max      429.000000\n",
       "Name: city_id, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### unsure about this filtering - depends if data points are real or mistake\n",
    "print(\"dropping users with less than 4 trips\")\n",
    "df = df.loc[df[\"total_rows\"]>=4]#.copy()\n",
    "# print(\"abnormal users dropped\",df.shape[0]-df.shape[0])\n",
    "\n",
    "print(f\"dropping cities with less than {MIN_TARGET_FREQ} occurences:\")\n",
    "df = df.loc[df.groupby([\"city_id\"])[\"hotel_country\"].transform(\"count\")>=MIN_TARGET_FREQ] ## update count\n",
    "# df = df.loc[df[\"city_id_count\"]>=MIN_TARGET_FREQ]\n",
    "print(df.shape[0])\n",
    "\n",
    "# print(f\"dropping users with less than 4 instances, after previous city filter:\")\n",
    "df = df.loc[df.groupby([\"utrip_id\"])[TARGET_COL].transform(\"count\")>=4]\n",
    "\n",
    "# print(f\"dropping cities with less than {MIN_TARGET_FREQ} occurences:\")\n",
    "df = df.loc[df.groupby([\"city_id\"])[\"hotel_country\"].transform(\"count\")>=MIN_TARGET_FREQ]\n",
    "\n",
    "print(f\"dropping users with less than 4 instances, after previous filters:\")\n",
    "df = df.loc[df.groupby([\"utrip_id\"])[TARGET_COL].transform(\"count\")>=4]\n",
    "\n",
    "df = df.loc[df.groupby([\"city_id\"])[\"hotel_country\"].transform(\"count\")>=MIN_TARGET_FREQ]\n",
    "df = df.loc[df.groupby([\"utrip_id\"])[TARGET_COL].transform(\"count\")>=4]\n",
    "df = df.loc[df.groupby([\"city_id\"])[\"hotel_country\"].transform(\"count\")>=MIN_TARGET_FREQ]\n",
    "df = df.loc[df.groupby([\"utrip_id\"])[TARGET_COL].transform(\"count\")>=4]\n",
    "# df = df.loc[df.groupby([\"city_id\"])[\"hotel_country\"].transform(\"count\")>=MIN_TARGET_FREQ]\n",
    "# df = df.loc[df.groupby([\"utrip_id\"])[TARGET_COL].transform(\"count\")>=4]\n",
    "\n",
    "print(\"rows left:\",df.shape[0])\n",
    "\n",
    "print(\"nunique cities after freq filt\",df[[\"city_id\",\"utrip_id\",\"user_id\",\"hotel_country\"]].nunique())\n",
    "print(\"nunique city_id per hotel_country:\")\n",
    "df.groupby([\"hotel_country\"])[\"city_id\"].nunique().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* drop the first location visited per trip, as that shares the \"first country/hotel/city id feature\" ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702158\n"
     ]
    }
   ],
   "source": [
    "if DROP_FIRST_ROW: ## drop the first location visited per trip, (row_num = 1) from df data/interactions\n",
    "    df = df.loc[df[\"row_num\"]>1]\n",
    "    print(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values([ \"checkin\",\n",
    "                \"utrip_id\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utrip_id</th>\n",
       "      <th>city_id</th>\n",
       "      <th>label</th>\n",
       "      <th>checkin</th>\n",
       "      <th>user_id</th>\n",
       "      <th>checkout</th>\n",
       "      <th>device_class</th>\n",
       "      <th>affiliate_id</th>\n",
       "      <th>booker_country</th>\n",
       "      <th>hotel_country</th>\n",
       "      <th>checkin_week</th>\n",
       "      <th>checkin_month</th>\n",
       "      <th>checkin_quarter</th>\n",
       "      <th>row_num</th>\n",
       "      <th>total_rows</th>\n",
       "      <th>last</th>\n",
       "      <th>first_hotel_country</th>\n",
       "      <th>first_city_id</th>\n",
       "      <th>first_device_class</th>\n",
       "      <th>first_affiliate_id</th>\n",
       "      <th>first_checkin_quarter</th>\n",
       "      <th>first_checkin_month</th>\n",
       "      <th>first_booker_country</th>\n",
       "      <th>city_id_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>519018</th>\n",
       "      <td>727105_1</td>\n",
       "      <td>60403</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>727105</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>mobile</td>\n",
       "      <td>359</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>Cobra Island</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Cobra Island</td>\n",
       "      <td>60403</td>\n",
       "      <td>mobile</td>\n",
       "      <td>359</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805583</th>\n",
       "      <td>1032571_1</td>\n",
       "      <td>48483</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>1032571</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>mobile</td>\n",
       "      <td>9924</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>Cobra Island</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Cobra Island</td>\n",
       "      <td>21996</td>\n",
       "      <td>mobile</td>\n",
       "      <td>9924</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>5731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52885</th>\n",
       "      <td>110418_1</td>\n",
       "      <td>3763</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>110418</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>desktop</td>\n",
       "      <td>9924</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>Glubbdubdrib</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Glubbdubdrib</td>\n",
       "      <td>3763</td>\n",
       "      <td>desktop</td>\n",
       "      <td>9924</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>5544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368668</th>\n",
       "      <td>1204242_1</td>\n",
       "      <td>10485</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>1204242</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>desktop</td>\n",
       "      <td>2661</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>Kangan</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Kangan</td>\n",
       "      <td>5860</td>\n",
       "      <td>desktop</td>\n",
       "      <td>2661</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>5351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531558</th>\n",
       "      <td>1316608_1</td>\n",
       "      <td>41654</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>1316608</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>mobile</td>\n",
       "      <td>4888</td>\n",
       "      <td>Tcherkistan</td>\n",
       "      <td>Pullamawang</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Pullamawang</td>\n",
       "      <td>41654</td>\n",
       "      <td>mobile</td>\n",
       "      <td>4888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Tcherkistan</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244942</th>\n",
       "      <td>5955565_2</td>\n",
       "      <td>54384</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>5955565</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>desktop</td>\n",
       "      <td>8132</td>\n",
       "      <td>Elbonia</td>\n",
       "      <td>Patusan</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Elbonia</td>\n",
       "      <td>52327</td>\n",
       "      <td>desktop</td>\n",
       "      <td>8132</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Elbonia</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787249</th>\n",
       "      <td>6172320_1</td>\n",
       "      <td>6005</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>6172320</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>mobile</td>\n",
       "      <td>9452</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>Patusan</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Sokovia</td>\n",
       "      <td>34342</td>\n",
       "      <td>mobile</td>\n",
       "      <td>9452</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455641</th>\n",
       "      <td>885453_1</td>\n",
       "      <td>53020</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>885453</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>desktop</td>\n",
       "      <td>9924</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Santa Prisca</td>\n",
       "      <td>44103</td>\n",
       "      <td>desktop</td>\n",
       "      <td>9924</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175371</th>\n",
       "      <td>890798_1</td>\n",
       "      <td>43524</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>890798</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>desktop</td>\n",
       "      <td>9924</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Rolisica</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Santa Prisca</td>\n",
       "      <td>44103</td>\n",
       "      <td>desktop</td>\n",
       "      <td>9924</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008732</th>\n",
       "      <td>948323_6</td>\n",
       "      <td>47486</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>948323</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>desktop</td>\n",
       "      <td>4541</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Holy Britannian Empire</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Rolisica</td>\n",
       "      <td>8462</td>\n",
       "      <td>desktop</td>\n",
       "      <td>4541</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>2593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>702158 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          utrip_id  city_id  label    checkin  user_id    checkout  \\\n",
       "519018    727105_1    60403      1 2016-01-01   727105  2016-01-02   \n",
       "805583   1032571_1    48483      1 2016-01-02  1032571  2016-01-04   \n",
       "52885     110418_1     3763      1 2016-01-02   110418  2016-01-03   \n",
       "368668   1204242_1    10485      1 2016-01-02  1204242  2016-01-03   \n",
       "531558   1316608_1    41654      1 2016-01-02  1316608  2016-01-03   \n",
       "...            ...      ...    ...        ...      ...         ...   \n",
       "244942   5955565_2    54384      1 2017-02-27  5955565  2017-02-28   \n",
       "787249   6172320_1     6005      1 2017-02-27  6172320  2017-02-28   \n",
       "455641    885453_1    53020      1 2017-02-27   885453  2017-02-28   \n",
       "175371    890798_1    43524      1 2017-02-27   890798  2017-02-28   \n",
       "1008732   948323_6    47486      1 2017-02-27   948323  2017-02-28   \n",
       "\n",
       "        device_class  affiliate_id        booker_country  \\\n",
       "519018        mobile           359  The Devilfire Empire   \n",
       "805583        mobile          9924  The Devilfire Empire   \n",
       "52885        desktop          9924  The Devilfire Empire   \n",
       "368668       desktop          2661  The Devilfire Empire   \n",
       "531558        mobile          4888           Tcherkistan   \n",
       "...              ...           ...                   ...   \n",
       "244942       desktop          8132               Elbonia   \n",
       "787249        mobile          9452  The Devilfire Empire   \n",
       "455641       desktop          9924                Gondal   \n",
       "175371       desktop          9924                Gondal   \n",
       "1008732      desktop          4541                Gondal   \n",
       "\n",
       "                  hotel_country  checkin_week  checkin_month  checkin_quarter  \\\n",
       "519018             Cobra Island            53              1                1   \n",
       "805583             Cobra Island            53              1                1   \n",
       "52885              Glubbdubdrib            53              1                1   \n",
       "368668                   Kangan            53              1                1   \n",
       "531558              Pullamawang            53              1                1   \n",
       "...                         ...           ...            ...              ...   \n",
       "244942                  Patusan             9              2                1   \n",
       "787249                  Patusan             9              2                1   \n",
       "455641                   Gondal             9              2                1   \n",
       "175371                 Rolisica             9              2                1   \n",
       "1008732  Holy Britannian Empire             9              2                1   \n",
       "\n",
       "         row_num  total_rows  last first_hotel_country  first_city_id  \\\n",
       "519018         2           4     0        Cobra Island          60403   \n",
       "805583         2           5     0        Cobra Island          21996   \n",
       "52885          2          10     0        Glubbdubdrib           3763   \n",
       "368668         2           5     0              Kangan           5860   \n",
       "531558         2           5     0         Pullamawang          41654   \n",
       "...          ...         ...   ...                 ...            ...   \n",
       "244942         5           5     1             Elbonia          52327   \n",
       "787249        10          10     1             Sokovia          34342   \n",
       "455641         4           4     1        Santa Prisca          44103   \n",
       "175371         4           4     1        Santa Prisca          44103   \n",
       "1008732        8           8     1            Rolisica           8462   \n",
       "\n",
       "        first_device_class  first_affiliate_id  first_checkin_quarter  \\\n",
       "519018              mobile                 359                      1   \n",
       "805583              mobile                9924                      1   \n",
       "52885              desktop                9924                      1   \n",
       "368668             desktop                2661                      1   \n",
       "531558              mobile                4888                      1   \n",
       "...                    ...                 ...                    ...   \n",
       "244942             desktop                8132                      1   \n",
       "787249              mobile                9452                      1   \n",
       "455641             desktop                9924                      1   \n",
       "175371             desktop                9924                      1   \n",
       "1008732            desktop                4541                      1   \n",
       "\n",
       "         first_checkin_month  first_booker_country  city_id_count  \n",
       "519018                     1  The Devilfire Empire            565  \n",
       "805583                     1  The Devilfire Empire           5731  \n",
       "52885                      1  The Devilfire Empire           5544  \n",
       "368668                     1  The Devilfire Empire           5351  \n",
       "531558                     1           Tcherkistan            325  \n",
       "...                      ...                   ...            ...  \n",
       "244942                     2               Elbonia            526  \n",
       "787249                     2  The Devilfire Empire            367  \n",
       "455641                     2                Gondal            141  \n",
       "175371                     2                Gondal            514  \n",
       "1008732                    2                Gondal           2593  \n",
       "\n",
       "[702158 rows x 24 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"] = 1\n",
    "\n",
    "## rearrange columns - user, item, and label column index are 0, 1, and 2\n",
    "# new_columns = cols_to_order + (frame.columns.drop(cols_to_order).tolist())\n",
    "cols_to_order = [\"utrip_id\",\"city_id\",\"label\",\"checkin\"]\n",
    "new_columns = cols_to_order + (df.columns.drop(cols_to_order).tolist())\n",
    "\n",
    "df = df[new_columns]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(702158, 10)\n",
      "(669859, 10)\n",
      "['user', 'item', 'time', 'hotel_country', 'first_hotel_country', 'first_city_id', 'first_device_class', 'first_affiliate_id', 'first_booker_country']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>label</th>\n",
       "      <th>time</th>\n",
       "      <th>hotel_country</th>\n",
       "      <th>first_hotel_country</th>\n",
       "      <th>first_city_id</th>\n",
       "      <th>first_device_class</th>\n",
       "      <th>first_affiliate_id</th>\n",
       "      <th>first_booker_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>519018</th>\n",
       "      <td>727105_1</td>\n",
       "      <td>60403</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Cobra Island</td>\n",
       "      <td>Cobra Island</td>\n",
       "      <td>60403</td>\n",
       "      <td>mobile</td>\n",
       "      <td>359</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805583</th>\n",
       "      <td>1032571_1</td>\n",
       "      <td>48483</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>Cobra Island</td>\n",
       "      <td>Cobra Island</td>\n",
       "      <td>21996</td>\n",
       "      <td>mobile</td>\n",
       "      <td>9924</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52885</th>\n",
       "      <td>110418_1</td>\n",
       "      <td>3763</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>Glubbdubdrib</td>\n",
       "      <td>Glubbdubdrib</td>\n",
       "      <td>3763</td>\n",
       "      <td>desktop</td>\n",
       "      <td>9924</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368668</th>\n",
       "      <td>1204242_1</td>\n",
       "      <td>10485</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>Kangan</td>\n",
       "      <td>Kangan</td>\n",
       "      <td>5860</td>\n",
       "      <td>desktop</td>\n",
       "      <td>2661</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531558</th>\n",
       "      <td>1316608_1</td>\n",
       "      <td>41654</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>Pullamawang</td>\n",
       "      <td>Pullamawang</td>\n",
       "      <td>41654</td>\n",
       "      <td>mobile</td>\n",
       "      <td>4888</td>\n",
       "      <td>Tcherkistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244942</th>\n",
       "      <td>5955565_2</td>\n",
       "      <td>54384</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>Patusan</td>\n",
       "      <td>Elbonia</td>\n",
       "      <td>52327</td>\n",
       "      <td>desktop</td>\n",
       "      <td>8132</td>\n",
       "      <td>Elbonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787249</th>\n",
       "      <td>6172320_1</td>\n",
       "      <td>6005</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>Patusan</td>\n",
       "      <td>Sokovia</td>\n",
       "      <td>34342</td>\n",
       "      <td>mobile</td>\n",
       "      <td>9452</td>\n",
       "      <td>The Devilfire Empire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455641</th>\n",
       "      <td>885453_1</td>\n",
       "      <td>53020</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Santa Prisca</td>\n",
       "      <td>44103</td>\n",
       "      <td>desktop</td>\n",
       "      <td>9924</td>\n",
       "      <td>Gondal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175371</th>\n",
       "      <td>890798_1</td>\n",
       "      <td>43524</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>Rolisica</td>\n",
       "      <td>Santa Prisca</td>\n",
       "      <td>44103</td>\n",
       "      <td>desktop</td>\n",
       "      <td>9924</td>\n",
       "      <td>Gondal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008732</th>\n",
       "      <td>948323_6</td>\n",
       "      <td>47486</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>Holy Britannian Empire</td>\n",
       "      <td>Rolisica</td>\n",
       "      <td>8462</td>\n",
       "      <td>desktop</td>\n",
       "      <td>4541</td>\n",
       "      <td>Gondal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>669859 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              user   item  label       time           hotel_country  \\\n",
       "519018    727105_1  60403      1 2016-01-01            Cobra Island   \n",
       "805583   1032571_1  48483      1 2016-01-02            Cobra Island   \n",
       "52885     110418_1   3763      1 2016-01-02            Glubbdubdrib   \n",
       "368668   1204242_1  10485      1 2016-01-02                  Kangan   \n",
       "531558   1316608_1  41654      1 2016-01-02             Pullamawang   \n",
       "...            ...    ...    ...        ...                     ...   \n",
       "244942   5955565_2  54384      1 2017-02-27                 Patusan   \n",
       "787249   6172320_1   6005      1 2017-02-27                 Patusan   \n",
       "455641    885453_1  53020      1 2017-02-27                  Gondal   \n",
       "175371    890798_1  43524      1 2017-02-27                Rolisica   \n",
       "1008732   948323_6  47486      1 2017-02-27  Holy Britannian Empire   \n",
       "\n",
       "        first_hotel_country  first_city_id first_device_class  \\\n",
       "519018         Cobra Island          60403             mobile   \n",
       "805583         Cobra Island          21996             mobile   \n",
       "52885          Glubbdubdrib           3763            desktop   \n",
       "368668               Kangan           5860            desktop   \n",
       "531558          Pullamawang          41654             mobile   \n",
       "...                     ...            ...                ...   \n",
       "244942              Elbonia          52327            desktop   \n",
       "787249              Sokovia          34342             mobile   \n",
       "455641         Santa Prisca          44103            desktop   \n",
       "175371         Santa Prisca          44103            desktop   \n",
       "1008732            Rolisica           8462            desktop   \n",
       "\n",
       "         first_affiliate_id  first_booker_country  \n",
       "519018                  359  The Devilfire Empire  \n",
       "805583                 9924  The Devilfire Empire  \n",
       "52885                  9924  The Devilfire Empire  \n",
       "368668                 2661  The Devilfire Empire  \n",
       "531558                 4888           Tcherkistan  \n",
       "...                     ...                   ...  \n",
       "244942                 8132               Elbonia  \n",
       "787249                 9452  The Devilfire Empire  \n",
       "455641                 9924                Gondal  \n",
       "175371                 9924                Gondal  \n",
       "1008732                4541                Gondal  \n",
       "\n",
       "[669859 rows x 10 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEEP_COLS = ['utrip_id', 'city_id', 'label',\n",
    "             \"checkin\",\n",
    "             \"hotel_country\", ## should be item feature \n",
    "             \n",
    "#               'user_id', 'checkin', 'checkout','device_class', 'affiliate_id',  'booker_country', \n",
    "#        'checkin_week', 'checkin_month', \n",
    "#               'row_num', \n",
    "#              'total_rows',\n",
    "#               'last',\n",
    "       'first_hotel_country',\n",
    "             'first_city_id', 'first_device_class','first_affiliate_id',\n",
    "#              'first_checkin_quarter',\n",
    "#              'first_checkin_month',\n",
    "       'first_booker_country'\n",
    "            ]\n",
    "             \n",
    "df = df[KEEP_COLS]        \n",
    "df.rename(columns={\"checkin\":\"time\",\n",
    "                  'utrip_id':\"user\",\n",
    "                   'city_id':\"item\"\n",
    "                  },inplace=True)\n",
    "print(df.shape)\n",
    "### opt: drop duplicates, +- time ? \n",
    "df.drop_duplicates(subset=['user', 'item', 'hotel_country', 'first_hotel_country',\n",
    "                           'first_city_id', 'first_booker_country'],inplace=True)\n",
    "print(df.shape)\n",
    "print(df.columns.drop(cols_to_order,errors=\"ignore\").tolist())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: (total positives/interactions, divided by all possible user/item combs in %, )\n",
      "0.11213488411403386\n",
      "0.11213488411403386\n"
     ]
    }
   ],
   "source": [
    "print(\"Sparsity: (total positives/interactions, divided by all possible user/item combs in %, )\")\n",
    "# print(100*df.shape[0] / (162904 * 3667))\n",
    "print(100*df.shape[0] / (df['user'].nunique() * df['item'].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"KMP_WARNINGS\"] = \"FALSE\"\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_state(\"YouTubeRanking\")\n",
    "# reset_state(\"YouTubeMatch\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ============================== YouTubeRanking ==============================\n",
      "trainset made\n",
      "testset made\n",
      "random neg item sampling elapsed: 1.895s\n",
      "train negs done\n",
      "random neg item sampling elapsed: 0.080s\n",
      "test negs done\n",
      "n_users: 162904, n_items: 3667, data sparsity: 0.0977 %\n",
      "Training start time: \u001b[35m2021-01-06 00:43:33\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|█████████████████████████████████████████████████████████████████████| 72965/72965 [18:15<00:00, 66.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 elapsed: 1097.925s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|█████████████████████████████████████████████████████████████████████| 72965/72965 [18:15<00:00, 66.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 elapsed: 1097.608s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|█████████████████████████████████████████████████████████████████████| 72965/72965 [18:15<00:00, 66.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 elapsed: 1097.297s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|█████████████████████████████████████████████████████████████████████| 72965/72965 [18:18<00:00, 66.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 elapsed: 1100.633s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|█████████████████████████████████████████████████████████████████████| 72965/72965 [18:14<00:00, 66.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 elapsed: 1096.692s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|█████████████████████████████████████████████████████████████████████| 72965/72965 [18:16<00:00, 66.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 elapsed: 1098.554s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|█████████████████████████████████████████████████████████████████████| 72965/72965 [18:15<00:00, 66.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 elapsed: 1096.930s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_pred: 100%|███████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 59.30it/s]\n",
      "eval_rec: 100%|███████████████████████████████████████████████████████████████████| 1000/1000 [00:07<00:00, 139.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2h 15min 44s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.806724466471789, 'roc_auc': 0.9827009283558722, 'precision': 0.0885, 'recall': 0.3468333333333333}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# train_data, test_data = split_by_ratio_chrono(df, test_size=0.15)\n",
    "train_data, test_data = split_by_ratio(df, test_size=0.2)\n",
    "\n",
    "# specify complete columns information\n",
    "sparse_col = ['first_hotel_country', \n",
    "#               'first_city_id','first_device_class','first_affiliate_id', \n",
    "              'first_booker_country',\n",
    "              'first_city_id', 'first_device_class','first_affiliate_id',\n",
    "             \"hotel_country\"]\n",
    "# dense_col = [] #['total_rows',\n",
    "#              'first_checkin_quarter', \n",
    "              #'first_checkin_month',]\n",
    "user_col = ['first_hotel_country','first_booker_country','first_city_id', 'first_device_class','first_affiliate_id']\n",
    "item_col = [\"hotel_country\"]\n",
    "\n",
    "# train_data, test_data = split_by_ratio(df[user_col+item_col+[\"label\"]+sparse_col+dense_col], test_size=0.15)\n",
    "\n",
    "# train_data, data_info = DatasetFeat.build_trainset(\n",
    "#     train_data, user_col, item_col, sparse_col, dense_col\n",
    "# )\n",
    "train_data, data_info = DatasetFeat.build_trainset(\n",
    "    train_data, item_col=item_col, sparse_col=sparse_col,user_col=user_col,\n",
    ")\n",
    "print(\"trainset made\")\n",
    "test_data = DatasetFeat.build_testset(test_data)\n",
    "print(\"testset made\")\n",
    "\n",
    "# sample negative items for each record\n",
    "train_data.build_negative_samples(data_info,num_neg=5)\n",
    "print(\"train negs done\")\n",
    "test_data.build_negative_samples(data_info,num_neg=1)\n",
    "print(\"test negs done\")\n",
    "print(data_info)  # n_users: 9058, n_items: 456, data sparsity: 0.7836 %\n",
    "## (min 25 cities): n_users: 162904, n_items: 3667, data sparsity: 0.0977 %\n",
    "\n",
    "# reset_state(\"YouTubeRanking\")\n",
    "# reset_state(\"YouTubeMatch\") \n",
    "### The YouTubeMatch model assumes no item features.  \n",
    "\n",
    "## YouTubeRanking  ## YouTubeMatch # DeepFM\n",
    "ytb_ranking = YouTubeRanking(task=\"ranking\", data_info=data_info,\n",
    "                             embed_size=16, n_epochs=7, lr=2e-4,\n",
    "                             batch_size=64, use_bn=True,\n",
    "                             hidden_units=\"128,64\") ## hidden_units=\"128,64,32\"\n",
    "\n",
    "ytb_ranking.fit(train_data, verbose=1, shuffle=True,\n",
    "                eval_data=test_data,\n",
    "                metrics=[ \"loss\", \"roc_auc\", \"precision\", \"recall\"]) # \"roc_auc\",\n",
    "\n",
    "\n",
    "print(ytb_ranking.evaluate(test_data,metrics=[ \"loss\", \"roc_auc\", \"precision\", \"recall\"],k=4))\n",
    "print(\"recall @90\",ytb_ranking.evaluate(test_data,metrics=[ \"recall\"],k=90))\n",
    "\n",
    "# # predict preference of user 1 to item 2333\n",
    "# print(\"prediction: \", ytb_ranking.predict(user=1, item=33))\n",
    "# # recommend 7 items for user 1\n",
    "# print(\"recommendation: \", ytb_ranking.recommend_user(user=1, n_rec=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### temporal split, min 25:   (results the same on random split ) \n",
    "train_data.build_negative_samples(data_info,num_neg=7)\n",
    "test_data.build_negative_samples(data_info,num_neg=1)\n",
    "\n",
    "train_data, test_data = split_by_ratio_chrono(df, test_size=0.15)\n",
    "ytb_ranking = YouTubeRanking(task=\"ranking\", data_info=data_info,\n",
    "                             embed_size=16, n_epochs=7, lr=2e-4,\n",
    "                             batch_size=64, use_bn=True,\n",
    "                             hidden_units=\"128,64\")\n",
    "============================== YouTubeRanking ==============================\n",
    "trainset made\n",
    "testset made\n",
    "random neg item sampling elapsed: 1.895s\n",
    "train negs done\n",
    "random neg item sampling elapsed: 0.080s\n",
    "test negs done\n",
    "n_users: 162904, n_items: 3667, data sparsity: 0.0977 %\n",
    "Training start time: 2021-01-06 00:43:33\n",
    "train: 100%| \n",
    "Epoch 7 elapsed: 1096.930s\n",
    "Wall time: 2h 15min 44s\n",
    "\n",
    "Eval (temporal split): \n",
    "* {'loss': 0.806, 'roc_auc': 0.982, 'precision': 0.0885, 'recall': 0.3468}\n",
    "* {recall @ 90 : 'recall': 0.771}\n",
    "\n",
    "\n",
    "On a random split with same model (might include train on train )  - results are same as with temporal split ; \n",
    "* {'loss': 0.806, 'roc_auc': 0.982, 'precision': 0.0885, 'recall': 0.3468}\n",
    "* recall @90 {'recall': 0.77}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset_state(\"YouTubeRanking\")\n",
    "# data = pd.read_csv(\"./sample_movielens_merged.csv\", sep=\",\", header=0)\n",
    "# data[\"label\"] = 1  # convert to implicit data and do negative sampling afterwards\n",
    "\n",
    "# # split into train and test data based on time\n",
    "# train_data, test_data = split_by_ratio_chrono(data, test_size=0.2)\n",
    "\n",
    "# # specify complete columns information\n",
    "# sparse_col = [\"sex\", \"occupation\", \"genre1\", \"genre2\", \"genre3\"]\n",
    "# dense_col = [\"age\"]\n",
    "# user_col = [\"sex\", \"age\", \"occupation\"]\n",
    "# item_col = [\"genre1\", \"genre2\", \"genre3\"]\n",
    "\n",
    "# train_data, data_info = DatasetFeat.build_trainset(\n",
    "#     train_data, user_col, item_col, sparse_col, dense_col\n",
    "# )\n",
    "# test_data = DatasetFeat.build_testset(test_data)\n",
    "# train_data.build_negative_samples(data_info)  # sample negative items for each record\n",
    "# test_data.build_negative_samples(data_info)\n",
    "# print(data_info)  # n_users: 5962, n_items: 3226, data sparsity: 0.4185 %\n",
    "\n",
    "# ytb_ranking = YouTubeRanking(task=\"ranking\", data_info=data_info, embed_size=16, \n",
    "#                              n_epochs=3, lr=1e-4, batch_size=512, use_bn=True, \n",
    "#                              hidden_units=\"128,64,32\")\n",
    "# ytb_ranking.fit(train_data, verbose=2, shuffle=True, eval_data=test_data,\n",
    "#                 metrics=[\"loss\", \"roc_auc\", \"precision\", \"recall\", \"map\", \"ndcg\"])\n",
    "\n",
    "# # predict preference of user 1 to item 2333\n",
    "# print(\"prediction: \", ytb_ranking.predict(user=1, item=2333))  \n",
    "# # recommend 7 items for user 1\n",
    "# print(\"recommendation(id, probability): \", ytb_ranking.recommend_user(user=1, n_rec=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
