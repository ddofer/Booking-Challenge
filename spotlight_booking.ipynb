{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\ProgramData\\Anaconda3\\envs\\pytorch\n",
      "\n",
      "  added / updated specs:\n",
      "    - cudatoolkit=10.2\n",
      "    - pytorch\n",
      "    - torchvision\n",
      "\n",
      "\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    }
   ],
   "source": [
    "# !conda install pandas numpy scipy ipython -y\n",
    "# !conda install -c maciejkula -c pytorch spotlight -y\n",
    "# !pip install spotlight\n",
    "\n",
    "!conda install pytorch torchvision  cudatoolkit=10.2 -c pytorch --force-reinstall -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append(\"../../\")\n",
    "import os\n",
    "# import papermill as pm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from reco_utils.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k, get_top_k_items, auc\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit, GridSearchCV, GroupKFold\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from spotlight.cross_validation import random_train_test_split, user_based_train_test_split\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "from spotlight.evaluation import mrr_score\n",
    "from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
    "from spotlight.cross_validation import user_based_train_test_split\n",
    "from spotlight.datasets.synthetic import generate_sequential\n",
    "from spotlight.evaluation import sequence_mrr_score\n",
    "from spotlight.sequence.implicit import ImplicitSequenceModel\n",
    "from spotlight.interactions import Interactions\n",
    "import torch\n",
    "from spotlight.evaluation import sequence_mrr_score,precision_recall_score\n",
    "# from spotlight.evaluation import sequence_precision_recall_score # https://maciejkula.github.io/spotlight/evaluation.html#spotlight.evaluation.sequence_precision_recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_precision_recall_score(model, test, k=10, exclude_preceding=False):\n",
    "    \"\"\"\n",
    "    https://maciejkula.github.io/spotlight/_modules/spotlight/evaluation.html#sequence_precision_recall_score\n",
    "    \n",
    "    Compute sequence precision and recall scores. Each sequence\n",
    "    in test is split into two parts: the first part, containing\n",
    "    all but the last k elements, is used to predict the last k\n",
    "    elements.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    model: fitted instance of a recommender model\n",
    "        The model to evaluate.\n",
    "    test: :class:`spotlight.interactions.SequenceInteractions`\n",
    "        Test interactions.\n",
    "    exclude_preceding: boolean, optional\n",
    "        When true, items already present in the sequence will\n",
    "        be excluded from evaluation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    mrr scores: numpy array of shape (num_users,)\n",
    "        Array of MRR scores for each sequence in test.\n",
    "    \"\"\"\n",
    "    sequences = test.sequences[:, :-k]\n",
    "    targets = test.sequences[:, -k:]\n",
    "    precision_recalls = []\n",
    "    for i in range(len(sequences)):\n",
    "        predictions = -model.predict(sequences[i])\n",
    "        if exclude_preceding:\n",
    "            predictions[sequences[i]] = FLOAT_MAX\n",
    "\n",
    "        predictions = predictions.argsort()[:k]\n",
    "        precision_recall = _get_precision_recall(predictions, targets[i], k)\n",
    "        precision_recalls.append(precision_recall)\n",
    "\n",
    "    precision = np.array(precision_recalls)[:, 0]\n",
    "    recall = np.array(precision_recalls)[:, 1]\n",
    "    return precision, recall\n",
    "\n",
    "\n",
    "def _get_precision_recall(predictions, targets, k):\n",
    "\n",
    "    predictions = predictions[:k]\n",
    "    num_hit = len(set(predictions).intersection(set(targets)))\n",
    "\n",
    "    return float(num_hit) / len(predictions), float(num_hit) / len(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 4\n",
    "\n",
    "# Model parameters\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE =  256#1024\n",
    "\n",
    "SEED = 0  # Set None for non-deterministic results\n",
    "\n",
    "user_file = \"../../tests/resources/deeprec/lightgcn/user_embeddings.csv\"\n",
    "item_file = \"../../tests/resources/deeprec/lightgcn/item_embeddings.csv\"\n",
    "\n",
    "TRAIN_FILE_PATH = os.path.normpath(r\"C:\\Users\\Dan Ofer\\Desktop\\Stuff\\booking_wisdom\\booking_train_set.csv\") #\"/content/drive/MyDrive/booking_wisdom/booking_train_set.csv\" #\"booking_train_set.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spotlight relevant examples:\n",
    "\n",
    "https://github.com/maciejkula/spotlight/blob/master/examples/movielens_sequence/movielens_sequence.py\n",
    "\n",
    "https://github.com/maciejkula/spotlight/issues/172\n",
    "* Dataset creation/loading + get predictions (sequence)\n",
    "\n",
    "Spotlight hyperparameter tuning:\n",
    "https://github.com/maciejkula/spotlight/blob/master/examples/movielens_sequence/movielens_sequence.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = movielens.load_pandas_df(size=MOVIELENS_DATA_SIZE) ## orig \n",
    "# print(df.dtypes)\n",
    "# print(df.shape)\n",
    "# ## expected columns: ['userID', 'itemID', 'rating', 'timestamp'] (last as float), others as number\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max rows count    7496.000000\n",
      "mean        6.045624\n",
      "std         2.612190\n",
      "min         4.000000\n",
      "25%         4.000000\n",
      "50%         5.000000\n",
      "75%         7.000000\n",
      "max        23.000000\n",
      "Name: total_rows, dtype: float64\n",
      "nunique\n",
      " userID       1399\n",
      "itemID       2895\n",
      "timestamp     419\n",
      "dtype: int64\n",
      "(7012, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>0</td>\n",
       "      <td>61586</td>\n",
       "      <td>2016-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>0</td>\n",
       "      <td>15990</td>\n",
       "      <td>2016-10-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>0</td>\n",
       "      <td>28273</td>\n",
       "      <td>2016-10-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5728</th>\n",
       "      <td>0</td>\n",
       "      <td>47486</td>\n",
       "      <td>2016-10-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31114</td>\n",
       "      <td>2016-04-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      userID  itemID  timestamp\n",
       "5725       0   61586 2016-10-22\n",
       "5726       0   15990 2016-10-24\n",
       "5727       0   28273 2016-10-26\n",
       "5728       0   47486 2016-10-28\n",
       "0          1   31114 2016-04-09"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = movielens.load_pandas_df(size=MOVIELENS_DATA_SIZE) ## orig \n",
    "df = pd.read_csv(TRAIN_FILE_PATH,\n",
    "                     nrows=7_500,\n",
    "                     parse_dates=[\"checkin\"],infer_datetime_format=True,usecols=[\"utrip_id\",\"city_id\",\"checkin\"])\n",
    "user_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "## drop consecutive elements (need to do within group, and to order, and what about updating checkout date?)\n",
    "## 0 cases if we also use checkin or checkout. \n",
    "## The \"last\"  criteria does drop rows! Do we want or not want it???\n",
    "## We also +- need to merge with total duration data\n",
    "\n",
    "df[\"utrip_id\"] = user_encoder.fit_transform(df[\"utrip_id\"])\n",
    "df = df.groupby(\"utrip_id\").filter(lambda x: len(x) >= 4) # keep only trips with at least 4\n",
    "\n",
    "#####\n",
    "df[\"row_num\"] = df.groupby(\"utrip_id\")[\"checkin\"].rank(ascending=True,pct=False).astype(int)\n",
    "utrip_counts = df[\"utrip_id\"].value_counts()\n",
    "df[\"total_rows\"] = df[\"utrip_id\"].map(utrip_counts)\n",
    "print(\"max rows\", df[\"total_rows\"].describe())\n",
    "df[\"last\"] = (df[\"row_num\"] ==df[\"total_rows\"])#.astype(int)\n",
    "###\n",
    "df = df.loc[(df[[\"city_id\",\"utrip_id\",\"last\"]].shift() != df[[\"city_id\",\"utrip_id\",\"last\"]]).max(axis=1)]\n",
    "\n",
    "df = df[[\"utrip_id\",\"city_id\",\"checkin\",\"last\"]]\n",
    "              \n",
    "df.columns = ['userID', 'itemID',  'timestamp',\"last\"] ## no rating col\n",
    "\n",
    "df.sort_values([\"userID\",\"timestamp\"],ascending=True,inplace=True) ## reinforce sort order for within groups\n",
    "# df[\"rating\"] = 1\n",
    "\n",
    "df = df[['userID', 'itemID',  'timestamp']]\n",
    "# print(df.dtypes)\n",
    "print(\"nunique\\n\",df.nunique())\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique items (city_id)\n",
      "2895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    2895.000000\n",
       "mean        2.422107\n",
       "std         4.529493\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         2.000000\n",
       "max        62.000000\n",
       "Name: itemID, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"unique items (city_id)\")\n",
    "print(df['itemID'].nunique())\n",
    "df['itemID'].value_counts().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: 47499    62\n",
      "17127    61\n",
      "23921    59\n",
      "55128    53\n",
      "29770    53\n",
      "         ..\n",
      "53890     1\n",
      "27862     1\n",
      "32458     1\n",
      "64000     1\n",
      "34815     1\n",
      "Name: itemID, Length: 2895, dtype: int64\n",
      "uniques 2895\n",
      "unique items (city_id)\n",
      "565\n",
      "count     565.000000\n",
      "mean       12.410619\n",
      "std       116.150083\n",
      "min         3.000000\n",
      "25%         3.000000\n",
      "50%         5.000000\n",
      "75%         8.000000\n",
      "max      2761.000000\n",
      "Name: itemID, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "### replace rare variables (under 2 occurrences) with \"-1\" dummy OR with their hotel country! (as negative mapped number)\n",
    "city_ids_counts = df[\"itemID\"].value_counts()\n",
    "print(\"before:\", city_ids_counts)\n",
    "print(\"uniques\",df[\"itemID\"].nunique())\n",
    "city_ids_counts = city_ids_counts.to_dict()\n",
    "# df[\"itemID\"] = df[\"itemID\"].where(df[\"itemID\"].apply(lambda x: x.map(x.value_counts()))>=3, -1)\n",
    "df[\"itemID\"] = df[\"itemID\"].where(df[\"itemID\"].map(city_ids_counts)>2, -1)\n",
    "\n",
    "## run encoder on cities (due to negative and to ensure ok ordering for spotlight)\n",
    "item_encoder = LabelEncoder()\n",
    "df[\"itemID\"] = user_encoder.fit_transform(df[\"itemID\"])\n",
    "\n",
    "print(\"unique items (city_id)\")\n",
    "print(df['itemID'].nunique())\n",
    "print(df['itemID'].value_counts().describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[~(df[[\"city_id\",\"utrip_id\"]].shift() != df[[\"city_id\",\"utrip_id\"]]).max(axis=1)]\n",
    "# df.loc[~(df[[\"city_id\",\"utrip_id\",\"last\"]].shift() != df[[\"city_id\",\"utrip_id\",\"last\"]]).max(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ## Original:\n",
    "# train, test = python_stratified_split(df, ratio=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create spotlight Interactions dataset\n",
    "    * https://github.com/maciejkula/spotlight/issues/172\n",
    "    * Could provide WEIGHTS (more weight to final row in sequence / last) \n",
    "    \n",
    "    * Getting predictions: \n",
    "    ```\n",
    "    predictions = model.predict(ids)\n",
    "\n",
    "    item_ids= (-predictions).argsort()[:10] # last 10 items\n",
    "    print(item_ids)\n",
    "    print(predictions[item_ids])\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train <Interactions dataset (1402 users x 566 items x 5146 interactions)>\n",
      "test <Interactions dataset (1402 users x 566 items x 1866 interactions)>\n"
     ]
    }
   ],
   "source": [
    "implicit_interactions = Interactions(df['userID'].values, 1+df['itemID'].values, timestamps=df['timestamp'])\n",
    "\n",
    "train, test = user_based_train_test_split(implicit_interactions, 0.25) # ,random_state=\n",
    "print(\"train\",train)\n",
    "print(\"test\",test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OLD: manual train test split - only last item , for some users\n",
    "\n",
    "train_inds, test_inds = next(GroupShuffleSplit(test_size=.35, ## test_size=.35, # when getting only last\n",
    "                                               n_splits=2,\n",
    "                                               random_state = 0).split(df,groups=df['userID']))\n",
    "# X_train = df.iloc[train_inds]\n",
    "X_test = df.iloc[test_inds]\n",
    "\n",
    "train = pd.concat([df.iloc[train_inds],\n",
    "                  X_test.loc[X_test[\"last\"]==False]]).drop([\"last\"],axis=1)\n",
    "\n",
    "test = pd.concat([X_test.loc[X_test[\"last\"]==True]]).drop([\"last\"],axis=1)\n",
    "\n",
    "train.sort_values([\"userID\",\"timestamp\"],ascending=True,inplace=True)\n",
    "test.sort_values([\"userID\",\"timestamp\"],ascending=True,inplace=True)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sequential_interaction = train.to_sequence(max_sequence_length=9, min_sequence_length=3)\n",
    "print(sequential_interaction)\n",
    "test_sequential = test.to_sequence(max_sequence_length=16, min_sequence_length=4)\n",
    "print(test_sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "implicit_sequence_model = ImplicitSequenceModel(use_cuda=False, ##  error when running locally with pytorch - using wrong cuda version - dan windows\n",
    "                                                n_iter=5, \n",
    "                                                loss='bpr', # 'pointwise', 'bpr', 'hinge', 'adaptive_hinge'\n",
    "                                                representation='lstm', # 'pooling', 'cnn', 'lstm', 'mixture'\n",
    "                                               batch_size=256,\n",
    "                                               embedding_dim=64) #  , sparse=True\n",
    "implicit_sequence_model.fit(sequential_interaction, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision_recall_score(implicit_sequence_model, test, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://maciejkula.github.io/spotlight/evaluation.html#spotlight.evaluation.sequence_precision_recall_score\n",
    "## listed in spotlight docs, not found on import ? \n",
    "# Compute sequence precision and recall scores. \n",
    "# Each sequence in test is split into two parts: the first part, containing all but the last k elements, is used to predict the last k elements.\n",
    "\n",
    "\n",
    "### returns score per user\n",
    "seq_pr_score_array = sequence_precision_recall_score(implicit_sequence_model, test_sequential, k=1, exclude_preceding=False) \n",
    "\n",
    "print(\"pr_score_array[0].mean\",seq_pr_score_array[0].mean())\n",
    "print(\"pr_score_array[1].mean\",seq_pr_score_array[1].mean()) ## the 2 arrays appear identical  ? \n",
    "seq_pr_score_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (seq_pr_score_array[0] ==seq_pr_score_array[1]).mean() ## 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_pr_score_array[1].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dan: \n",
    "### Below this is old code from the ms recomenders notebook, not yet updated for new evaluation. Ignopre it for now! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Recommendation and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendation and evaluation have been performed on the specified test set during training. After training, we can also use the model to perform recommendation and evalution on other data. Here we still use `test` as test data, but `test` can be replaced by other data with similar data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1 Recommendation\n",
    "\n",
    "We can call `recommend_k_items` to recommend k items for each user passed in this function. \n",
    "(Originally - had set `remove_seen=True` to remove the items already seen by the user).\n",
    "The function returns a dataframe, containing each user and top k items recommended to them and the corresponding ranking scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get last row per user id (i.e final destination) - for evaluating predictions on last destination\n",
    "# warning - existing train test split is random, not for last.. model isn';t time aware! \n",
    "test_last = test.groupby(\"userID\").last().reset_index()[[\"userID\",\"itemID\"]]\n",
    "assert test[\"userID\"].nunique() == test_last.shape[0]\n",
    "test_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_scores = model.recommend_k_items(test, top_k=TOP_K+1,\n",
    "                                      remove_seen=False)\n",
    "\n",
    "## drop the rare values (we replaced with negatives) -since we don't know them. take next best prediction, then keep only top 4\n",
    "topk_scores = topk_scores.loc[topk_scores[\"itemID\"]>=0] \n",
    "## keep top 4\n",
    "topk_scores = topk_scores.groupby(\"userID\").head(4)#.reset_index()\n",
    "\n",
    "topk_scores\n",
    "topk_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topk_merged = topk_scores.merge(test_last,on=[\"userID\",\"itemID\"],how=\"right\")#.fillna(0) # nan/0 = not predicted\n",
    "display(topk_merged)\n",
    "print(topk_merged.isna().sum())\n",
    "print(\"Topk Accuracy: %.3f\" % (100*(1-(topk_merged[\"prediction\"].isna().sum())/topk_merged[\"userID\"].nunique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2 Evaluation\n",
    "\n",
    "With `topk_scores` predicted by the model, we can evaluate how LightGCN performs on this test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_map = map_at_k(test, topk_scores, k=TOP_K)\n",
    "eval_ndcg = ndcg_at_k(test, topk_scores, k=TOP_K)\n",
    "eval_precision = precision_at_k(test, topk_scores, k=TOP_K)\n",
    "eval_recall = recall_at_k(test, topk_scores, k=TOP_K)\n",
    "\n",
    "print(\"MAP:\\t%f\" % eval_map,\n",
    "      \"NDCG:\\t%f\" % eval_ndcg,\n",
    "      \"Precision@K:\\t%f\" % eval_precision,\n",
    "      \"Recall@K:\\t%f\" % eval_recall, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Infer embeddings\n",
    "\n",
    "With `infer_embedding` method of LightGCN model, we can export the embeddings of users and items in the training set to CSV files for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.infer_embedding(user_file, item_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Compare with SAR and NCF\n",
    "\n",
    "Here there are the performances of LightGCN compared to [SAR](../00_quick_start/sar_movielens.ipynb) and [NCF](../00_quick_start/ncf_movielens.ipynb) on MovieLens dataset of 100k and 1m. The method of data loading and splitting is the same as that described above and the GPU used was a GeForce GTX 1080Ti.\n",
    "\n",
    "Settings common to the three models: `epochs=15, seed=42`.\n",
    "\n",
    "Settings for LightGCN: `embed_size=64, n_layers=3, batch_size=1024, decay=0.0001, learning_rate=0.015 `.\n",
    "\n",
    "Settings for SAR: `similarity_type=\"jaccard\", time_decay_coefficient=30, time_now=None, timedecay_formula=True`.\n",
    "\n",
    "Settings for NCF: `n_factors=4, layer_sizes=[16, 8, 4], batch_size=1024, learning_rate=0.001`.\n",
    "\n",
    "| Data Size | Model    | Training time | Recommending time | MAP@10   | nDCG@10  | Precision@10 | Recall@10 |\n",
    "| --------- | -------- | ------------- | ----------------- | -------- | -------- | ------------ | --------- |\n",
    "| 100k      | LightGCN | 27.8865       | 0.6445            | 0.129236 | 0.436297 | 0.381866     | 0.205816  |\n",
    "| 100k      | SAR      | 0.4895        | 0.1144            | 0.110591 | 0.382461 | 0.330753     | 0.176385  |\n",
    "| 100k      | NCF      | 116.3174      | 7.7660            | 0.105725 | 0.387603 | 0.342100     | 0.174580  |\n",
    "| 1m        | LightGCN | 396.7298      | 1.4343            | 0.075012 | 0.377501 | 0.345679     | 0.128096  |\n",
    "| 1m        | SAR      | 4.5593        | 2.8357            | 0.060579 | 0.299245 | 0.270116     | 0.104350  |\n",
    "| 1m        | NCF      | 1601.5846     | 85.4567           | 0.062821 | 0.348770 | 0.320613     | 0.108121  |\n",
    "\n",
    "From the above results, we can see that LightGCN performs better than the other two models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference: \n",
    "1. Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang & Meng Wang, LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation, 2020, https://arxiv.org/abs/2002.02126\n",
    "\n",
    "2. LightGCN implementation [TensorFlow]: https://github.com/kuandeng/lightgcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
